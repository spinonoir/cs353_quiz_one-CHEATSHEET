2

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

and the switches that transport data, as well as the access networks and physical
media that connect end systems to the network core. We’ll learn that the Internet is
a network of networks, and we’ll learn how these networks connect with each other.
After having completed this overview of the edge and core of a computer network, we’ll take the broader and more abstract view in the second half of this chapter. We’ll examine delay, loss, and throughput of data in a computer network and
provide simple quantitative models for end-to-end throughput and delay: models
that take into account transmission, propagation, and queuing delays. We’ll then
introduce some of the key architectural principles in computer networking, namely,
protocol layering and service models. We’ll also learn that computer networks are
vulnerable to many different types of attacks; we’ll survey some of these attacks and
consider how computer networks can be made more secure. Finally, we’ll close this
chapter with a brief history of computer networking.

1.1 What Is the Internet?
In this book, we’ll use the public Internet, a specific computer network, as our principal vehicle for discussing computer networks and their protocols. But what is the
Internet? There are a couple of ways to answer this question. First, we can describe
the nuts and bolts of the Internet, that is, the basic hardware and software components
that make up the Internet. Second, we can describe the Internet in terms of a networking infrastructure that provides services to distributed applications. Let’s begin with
the nuts-and-bolts description, using Figure 1.1 to illustrate our discussion.

1.1.1 A Nuts-and-Bolts Description
The Internet is a computer network that interconnects billions of computing devices
throughout the world. Not too long ago, these computing devices were primarily
traditional desktop computers, Linux workstations, and so-called servers that store
and transmit information such as Web pages and e-mail messages. Increasingly,
however, users connect to the Internet with smartphones and tablets—today, close
to half of the world’s population are active mobile Internet users with the percentage
expected to increase to 75% by 2025 [Statista 2019]. Furthermore, nontraditional
Internet “things” such as TVs, gaming consoles, thermostats, home security systems,
home appliances, watches, eye glasses, cars, traffic control systems, and more are
being connected to the Internet. Indeed, the term computer network is beginning to
sound a bit dated, given the many nontraditional devices that are being hooked up to
the Internet. In Internet jargon, all of these devices are called hosts or end systems.
By some estimates, there were about 18 billion devices connected to the Internet in
2017, and the number will reach 28.5 billion by 2022 [Cisco VNI 2020].

1.1

•

WHAT IS THE INTERNET?

National or
Global ISP

Mobile Network
Datacenter Network

Datacenter Network

Local or
Regional ISP

Home Network

Content Provider Network

Enterprise Network
Key:

Host
(= end system)

Datacenter

Server

Workstation

Mobile
Computer

Router

Traffic light

Link-layer
switch

Thermostat

Base
station

Fridge

Figure 1.1 ♦ Some pieces of the Internet

Smartphone
or tablet

Cell phone
tower

3

4

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

End systems are connected together by a network of communication links and
packet switches. We’ll see in Section 1.2 that there are many types of communication links, which are made up of different types of physical media, including coaxial
cable, copper wire, optical fiber, and radio spectrum. Different links can transmit
data at different rates, with the transmission rate of a link measured in bits/second.
When one end system has data to send to another end system, the sending end system
segments the data and adds header bytes to each segment. The resulting packages
of information, known as packets in the jargon of computer networks, are then sent
through the network to the destination end system, where they are reassembled into
the original data.
A packet switch takes a packet arriving on one of its incoming communication
links and forwards that packet on one of its outgoing communication links. Packet
switches come in many shapes and flavors, but the two most prominent types in
today’s Internet are routers and link-layer switches. Both types of switches forward
packets toward their ultimate destinations. Link-layer switches are typically used in
access networks, while routers are typically used in the network core. The sequence
of communication links and packet switches traversed by a packet from the sending end system to the receiving end system is known as a route or path through
the!network. Cisco predicts annual global IP traffic will reach nearly five zettabytes
(1021!bytes) by 2022 [Cisco VNI 2020].
Packet-switched networks (which transport packets) are in many ways
similar to transportation networks of highways, roads, and intersections (which
transport vehicles). Consider, for example, a factory that needs to move a large
amount of cargo to some destination warehouse located thousands of kilometers
away. At the factory, the cargo is segmented and loaded into a fleet of trucks.
Each of the trucks then independently travels through the network of highways,
roads, and intersections to the destination warehouse. At the destination warehouse, the cargo is unloaded and grouped with the rest of the cargo arriving
from the same shipment. Thus, in many ways, packets are analogous to trucks,
communication links are analogous to highways and roads, packet switches are
analogous to intersections, and end systems are analogous to buildings. Just as
a truck takes a path through the transportation network, a packet takes a path
through a computer network.
End systems access the Internet through Internet Service Providers (ISPs),
including residential ISPs such as local cable or telephone companies; corporate ISPs; university ISPs; ISPs that provide WiFi access in airports, hotels, coffee shops, and other public places; and cellular data ISPs, providing mobile access
to our smartphones and other devices. Each ISP is in itself a network of packet
switches and communication links. ISPs provide a variety of types of network access
to the end systems, including residential broadband access such as cable modem
or DSL, high-speed local area network access, and mobile wireless access. ISPs
also provide! Internet access to content providers, connecting servers directly to
the Internet. The Internet is all about connecting end systems to each other, so the

1.1

•

WHAT IS THE INTERNET?

ISPs!that provide access to end systems must also be interconnected. These lowertier ISPs are thus interconnected through national and international upper-tier ISPs
and these upper-tier ISPs are connected directly to each other. An upper-tier ISP
consists of high-speed routers interconnected with high-speed fiber-optic links. Each
ISP network, whether upper-tier or lower-tier, is managed independently, runs the
IP protocol (see below), and conforms to certain naming and address conventions.
We’ll examine ISPs and their interconnection more closely in Section 1.3.
End systems, packet switches, and other pieces of the Internet run protocols that
control the sending and receiving of information within the Internet. The Transmission
Control Protocol (TCP) and the Internet Protocol (IP) are two of the most important protocols in the Internet. The IP protocol specifies the format of the packets
that are sent and received among routers and end systems. The Internet’s principal
protocols are collectively known as TCP/IP. We’ll begin looking into protocols in
this introductory chapter. But that’s just a start—much of this book is concerned with
networking protocols!
Given the importance of protocols to the Internet, it’s important that everyone
agree on what each and every protocol does, so that people can create systems and
products that interoperate. This is where standards come into play. Internet standards
are developed by the Internet Engineering Task Force (IETF) [IETF 2020]. The IETF
standards documents are called requests for comments (RFCs). RFCs started out
as general requests for comments (hence the name) to resolve network and protocol
design problems that faced the precursor to the Internet [Allman 2011]. RFCs tend
to!be quite technical and detailed. They define protocols such as TCP, IP, HTTP (for
the Web), and SMTP (for e-mail). There are currently nearly 9000 RFCs. Other bodies also specify standards for network components, most notably for network links.
The IEEE 802 LAN Standards Committee [IEEE 802 2020], for example, specifies
the Ethernet and wireless WiFi standards.

1.1.2 A Services Description
Our discussion above has identified many of the pieces that make up the Internet.
But we can also describe the Internet from an entirely different angle—namely, as
an infrastructure that provides services to applications. In addition to traditional
applications such as e-mail and Web surfing, Internet applications include mobile
smartphone and tablet applications, including Internet messaging, mapping with
real-time road-traffic information, music streaming movie and television streaming,
online social media, video conferencing, multi-person games, and location-based
recommendation systems. The applications are said to be distributed applications,
since they involve multiple end systems that exchange data with each other. Importantly, Internet applications run on end systems—they do not run in the packet
switches in the network core. Although packet switches facilitate the exchange of
data among end systems, they are not concerned with the application that is the
source or sink of data.

5

6

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

Let’s explore a little more what we mean by an infrastructure that provides
services to applications. To this end, suppose you have an exciting new idea for a distributed Internet application, one that may greatly benefit humanity or one that may
simply make you rich and famous. How might you go about transforming this idea
into an actual Internet application? Because applications run on end systems, you are
going to need to write programs that run on the end systems. You might, for example,
write your programs in Java, C, or Python. Now, because you are developing a distributed Internet application, the programs running on the different end systems will
need to send data to each other. And here we get to a central issue—one that leads
to the alternative way of describing the Internet as a platform for applications. How
does one program running on one end system instruct the Internet to deliver data to
another program running on another end system?
End systems attached to the Internet provide a socket interface that specifies how a program running on one end system asks the Internet infrastructure to
deliver data to a specific destination program running on another end system. This
Internet socket interface is a set of rules that the sending program must follow so
that the Internet can deliver the data to the destination program. We’ll discuss the
Internet socket interface in detail in Chapter 2. For now, let’s draw upon a simple
analogy, one that we will frequently use in this book. Suppose Alice wants to send
a letter to Bob using the postal service. Alice, of course, can’t just write the letter
(the data) and drop the letter out her window. Instead, the postal service requires
that Alice put the letter in an envelope; write Bob’s full name, address, and zip
code in the center of the envelope; seal the envelope; put a stamp in the upperright-hand corner of the envelope; and finally, drop the envelope into an official
postal service mailbox. Thus, the postal service has its own “postal service interface,” or set of rules, that Alice must follow to have the postal service deliver her
letter to Bob. In a similar manner, the Internet has a socket interface that the program sending data must follow to have the Internet deliver the data to the program
that will receive the data.
The postal service, of course, provides more than one service to its customers. It provides express delivery, reception confirmation, ordinary use, and many
more services. In a similar manner, the Internet provides multiple services to its
applications. When you develop an Internet application, you too must choose one
of the Internet’s services for your application. We’ll describe the Internet’s services in Chapter 2.
We have just given two descriptions of the Internet; one in terms of its hardware
and software components, the other in terms of an infrastructure for providing services to distributed applications. But perhaps you are still confused as to what the
Internet is. What are packet switching and TCP/IP? What are routers? What kinds of
communication links are present in the Internet? What is a distributed application?
How can a thermostat or body scale be attached to the Internet? If you feel a bit overwhelmed by all of this now, don’t worry—the purpose of this book is to introduce
you to both the nuts and bolts of the Internet and the principles that govern how and

1.1

•

WHAT IS THE INTERNET?

why it works. We’ll explain these important terms and questions in the following
sections and chapters.

1.1.3 What Is a Protocol?
Now that we’ve got a bit of a feel for what the Internet is, let’s consider another
important buzzword in computer networking: protocol. What is a protocol? What
does a protocol do?

A Human Analogy
It is probably easiest to understand the notion of a computer network protocol by
first considering some human analogies, since we humans execute protocols all of
the time. Consider what you do when you want to ask someone for the time of day.
A typical exchange is shown in Figure 1.2. Human protocol (or good manners, at

TCP

Hi

Hi

Got

co

TCP
GET

the

conn

time

?

htt

ectio

n re

ctio
nne

que

n re

st

ply

p:/

/ww
w.p
ear
csson
res
hig
our
her
ces
ed.
/
com

/

2:00

Time

<file

Time

Time

Figure 1.2 ♦ A human protocol and a computer network protocol

>

Time

7

8

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

least) dictates that one first offer a greeting (the first “Hi” in Figure 1.2) to initiate
communication with someone else. The typical response to a “Hi” is a returned
“Hi” message. Implicitly, one then takes a cordial “Hi” response as an indication
that one can proceed and ask for the time of day. A different response to the initial
“Hi” (such as “Don’t bother me!” or “I don’t speak English,” or some unprintable
reply) might indicate an unwillingness or inability to communicate. In this case,
the human protocol would be not to ask for the time of day. Sometimes one gets no
response at all to a question, in which case one typically gives up asking that person
for the time. Note that in our human protocol, there are specific messages we send,
and specific actions we take in response to the received reply messages or other
events (such as no reply within some given amount of time). Clearly, transmitted
and received messages, and actions taken when these messages are sent or received
or other events occur, play a central role in a human protocol. If people run different protocols (for example, if one person has manners but the other does not, or if
one understands the concept of time and the other does not) the protocols do not
interoperate and no useful work can be accomplished. The same is true in networking—it takes two (or more) communicating entities running the same protocol in
order to accomplish a task.
Let’s consider a second human analogy. Suppose you’re in a college class (a
computer networking class, for example!). The teacher is droning on about protocols
and you’re confused. The teacher stops to ask, “Are there any questions?” (a message
that is transmitted to, and received by, all students who are not sleeping). You raise
your hand (transmitting an implicit message to the teacher). Your teacher acknowledges you with a smile, saying “Yes . . .” (a transmitted message encouraging you
to ask your question—teachers love to be asked questions), and you then ask your
question (that is, transmit your message to your teacher). Your teacher hears your
question (receives your question message) and answers (transmits a reply to you).
Once again, we see that the transmission and receipt of messages, and a set of conventional actions taken when these messages are sent and received, are at the heart
of this question-and-answer protocol.

Network Protocols
A network protocol is similar to a human protocol, except that the entities exchanging messages and taking actions are hardware or software components of some
device (for example, computer, smartphone, tablet, router, or other network-capable
device). All activity in the Internet that involves two or more communicating remote
entities is governed by a protocol. For example, hardware-implemented protocols in
two physically connected computers control the flow of bits on the “wire” between
the two network interface cards; congestion-control protocols in end systems control
the rate at which packets are transmitted between sender and receiver; protocols in
routers determine a packet’s path from source to destination. Protocols are running

1.2

•

THE NETWORK EDGE

everywhere in the Internet, and consequently much of this book is about computer
network protocols.
As an example of a computer network protocol with which you are probably
familiar, consider what happens when you make a request to a Web server, that
is, when you type the URL of a Web page into your Web browser. The scenario is
illustrated in the right half of Figure 1.2. First, your computer will send a connection request message to the Web server and wait for a reply. The Web server will
eventually receive your connection request message and return a connection reply
message. Knowing that it is now OK to request the Web document, your computer
then sends the name of the Web page it wants to fetch from that Web server in a
GET message. Finally, the Web server returns the Web page (file) to your computer.
Given the human and networking examples above, the exchange of messages
and the actions taken when these messages are sent and received are the key defining
elements of a protocol:
A protocol defines the format and the order of messages exchanged between two
or more communicating entities, as well as the actions taken on the transmission
and/or receipt of a message or other event.
The Internet, and computer networks in general, make extensive use of protocols. Different protocols are used to accomplish different communication tasks.
As you read through this book, you will learn that some protocols are simple and
straightforward, while others are complex and intellectually deep. Mastering the
field of computer networking is equivalent to understanding the what, why, and how
of networking protocols.

1.2 The Network Edge
In the previous section, we presented a high-level overview of the Internet and
networking protocols. We are now going to delve a bit more deeply into the components of the Internet. We begin in this section at the edge of the network and
look at the components with which we are most familiar—namely, the computers,
smartphones and other devices that we use on a daily basis. In the next section, we’ll
move from the network edge to the network core and examine switching and routing
in computer networks.
Recall from the previous section that in computer networking jargon, the computers and other devices connected to the Internet are often referred to as end systems. They are referred to as end systems because they sit at the edge of the Internet,
as shown in Figure 1.3. The Internet’s end systems include desktop computers

9

10

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

National or
Global ISP

Mobile Network
Datacenter Network

Datacenter Network

Home Network

Local or
Regional ISP

Content Provider Network

Enterprise Network

Figure 1.3 ♦ End-system interaction

(e.g., desktop PCs, Macs, and Linux boxes), servers (e.g., Web and e-mail servers),
and mobile devices (e.g., laptops, smartphones, and tablets). Furthermore, an
increasing number of non-traditional “things” are being attached to the Internet as
end systems (see the Case History feature).
End systems are also referred to as hosts because they host (that is, run) application programs such as a Web browser program, a Web server program, an e-mail

1.2

•

THE NETWORK EDGE

CASE HISTORY
DAT A CEN T ERS AND CLOUD CO M P UTI NG
Internet companies such as Google, Microsoft, Amazon, and Alibaba have built
massive data centers, each housing tens to hundreds of thousands of hosts. These
data centers are not only connected to the Internet, as shown in Figure 1.1, but also
internally include complex computer networks that interconnect the datacenter’s hosts.
The data centers are the engines behind the Internet applications that we use on a
daily basis.
Broadly speaking, data centers serve three purposes, which we describe here in
the context of Amazon for concreteness. First, they serve Amazon e-commerce pages
to users, for example, pages describing products and purchase information. Second,
they serve as massively parallel computing infrastructures for Amazon-specific data
processing tasks. Third, they provide cloud computing to other companies. Indeed,
today a major trend in computing is for companies to use a cloud provider such as
Amazon to handle essentially all of their IT needs. For example, Airbnb and many
other Internet-based companies do not own and manage their own data centers but
instead run their entire Web-based services in the Amazon cloud, called Amazon
Web Services (AWS).
The worker bees in a data center are the hosts. They serve content (e.g., Web
pages and videos), store e-mails and documents, and collectively perform massively
distributed computations. The hosts in data centers, called blades and resembling
pizza boxes, are generally commodity hosts that include CPU, memory, and disk
storage. The hosts are stacked in racks, with each rack typically having 20 to
40 blades. The racks are then interconnected using sophisticated and evolving data
center network designs. Data center networks are discussed in greater detail in
Chapter 6.

client program, or an e-mail server program. Throughout this book we will use the
terms hosts and end systems interchangeably; that is, host = end system. Hosts
are sometimes further divided into two categories: clients and servers. Informally, clients tend to be desktops, laptops, smartphones, and so on, whereas
servers tend to be more powerful machines that store and distribute Web pages,
stream video, relay e-mail, and so on. Today, most of the servers from which we
receive search results, e-mail, Web pages, videos and mobile app content reside
in large data centers. For example, as of 2020, Google has 19 data centers on four
continents, collectively containing several million servers. Figure 1.3 includes
two such data centers, and the Case History sidebar describes data centers in
more detail.

11

12

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

1.2.1 Access Networks
Having considered the applications and end systems at the “edge of the network,”
let’s next consider the access network—the network that physically connects an end
system to the first router (also known as the “edge router”) on a path from the end
system to any other distant end system. Figure 1.4 shows several types of access

National or
Global ISP

Mobile Network
Datacenter Network

Datacenter Network

Home Network

Local or
Regional ISP

Enterprise Network

Figure 1.4 ♦ Access networks

Content Provider Network

1.2

•

THE NETWORK EDGE

networks with thick, shaded lines and the settings (home, enterprise, and wide-area
mobile wireless) in which they are used.

Home Access: DSL, Cable, FTTH, and 5G Fixed Wireless
As of 2020, more than 80% of the households in Europe and the USA have Internet
access [Statista 2019]. Given this widespread use of home access networks let’s begin
our overview of access networks by considering how homes connect to the Internet.
Today, the two most prevalent types of broadband residential access are
digital subscriber line (DSL) and cable. A residence typically obtains DSL
Internet access from the same local telephone company (telco) that provides its
wired local phone access. Thus, when DSL is used, a customer’s telco is also
its ISP. As shown in Figure 1.5, each customer’s DSL modem uses the existing
telephone line exchange data with a digital subscriber line access multiplexer
(DSLAM) located in the telco’s local central office (CO). The home’s DSL
modem takes digital data and translates it to high-frequency tones for transmission over telephone wires to the CO; the analog signals from many such houses
are translated back into digital format at the DSLAM.
The residential telephone line carries both data and traditional telephone signals
simultaneously, which are encoded at different frequencies:
• A high-speed downstream channel, in the 50 kHz to 1 MHz band
• A medium-speed upstream channel, in the 4 kHz to 50 kHz band
• An ordinary two-way telephone channel, in the 0 to 4 kHz band
This approach makes the single DSL link appear as if there were three separate
links, so that a telephone call and an Internet connection can share the DSL link at
Home
phone

Internet
Existing phone line:
0-4KHz phone; 4-50KHz
upstream data; 50KHz–
1MHz downstream data

Splitter
DSL
modem
Home PC

Figure 1.5 ♦ DSL Internet access

Central
office

DSLAM

Telephone
network

13

14

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

the same time. (We’ll describe this technique of frequency-division multiplexing
in Section 1.3.1.) On the customer side, a splitter separates the data and telephone
signals arriving to the home and forwards the data signal to the DSL modem. On the
telco side, in the CO, the DSLAM separates the data and phone signals and sends
the data into the Internet. Hundreds or even thousands of households connect to a
single DSLAM.
The DSL standards define multiple transmission rates, including downstream
transmission rates of 24 Mbs and 52 Mbs, and upstream rates of 3.5 Mbps and
16!Mbps; the newest standard provides for aggregate upstream plus downstream
rates of 1 Gbps [ITU 2014]. Because the downstream and upstream rates are different, the access is said to be asymmetric. The actual downstream and upstream
transmission rates achieved may be less than the rates noted above, as the DSL
provider may purposefully limit a residential rate when tiered service (different
rates, available at different prices) are offered. The maximum rate is also limited
by the distance between the home and the CO, the gauge of the twisted-pair line
and the degree of electrical interference. Engineers have expressly designed DSL
for short distances between the home and the CO; generally, if the residence is not
located within 5 to 10 miles of the CO, the residence must resort to an alternative
form of Internet access.
While DSL makes use of the telco’s existing local telephone infrastructure,
cable Internet access makes use of the cable television company’s existing cable
television infrastructure. A residence obtains cable Internet access from the same
company that provides its cable television. As illustrated in Figure 1.6, fiber optics

Coaxial cable
Hundreds
of homes

Fiber
node

Fiber
cable

Internet

CMTS

Hundreds
of homes

Fiber
node

Cable head end

Figure 1.6 ♦ A hybrid fiber-coaxial access network

1.2

•

THE NETWORK EDGE

connect the cable head end to neighborhood-level junctions, from which traditional coaxial cable is then used to reach individual houses and apartments. Each
neighborhood junction typically supports 500 to 5,000 homes. Because both fiber
and coaxial cable are employed in this system, it is often referred to as hybrid fiber
coax (HFC).
Cable internet access requires special modems, called cable modems. As
with a DSL modem, the cable modem is typically an external device and connects to the home PC through an Ethernet port. (We will discuss Ethernet in
great detail in Chapter 6.) At the cable head end, the cable modem termination
system (CMTS) serves a similar function as the DSL network’s DSLAM—
turning the analog signal sent from the cable modems in many downstream
homes back into digital format. Cable modems divide the HFC network into two
channels, a downstream and an upstream channel. As with DSL, access is typically asymmetric, with the downstream channel typically allocated a higher
transmission rate than the upstream channel. The DOCSIS 2.0 and 3.0 standards
define downstream bitrates of 40 Mbps and 1.2 Gbps, and upstream rates
of 30 Mbps and 100 Mbps, respectively. As in the case of DSL networks, the
maximum achievable rate may not be realized due to lower contracted data rates
or media impairments.
One important characteristic of cable Internet access is that it is a shared broadcast medium. In particular, every packet sent by the head end travels downstream on
every link to every home and every packet sent by a home travels on the upstream
channel to the head end. For this reason, if several users are simultaneously downloading a video file on the downstream channel, the actual rate at which each user
receives its video file will be significantly lower than the aggregate cable downstream rate. On the other hand, if there are only a few active users and they are all
Web surfing, then each of the users may actually receive Web pages at the full cable
downstream rate, because the users will rarely request a Web page at exactly the
same time. Because the upstream channel is also shared, a distributed multiple access
protocol is needed to coordinate transmissions and avoid collisions. (We’ll discuss
this collision issue in some detail in Chapter 6.)
Although DSL and cable networks currently represent the majority of residential
broadband access in the United States, an up-and-coming technology that provides
even higher speeds is fiber to the home (FTTH) [Fiber Broadband 2020]. As the
name suggests, the FTTH concept is simple—provide an optical fiber path from
the!CO directly to the home. FTTH can potentially provide Internet access rates in
the gigabits per second range.
There are several competing technologies for optical distribution from the CO
to the homes. The simplest optical distribution network is called direct fiber, with
one fiber leaving the CO for each home. More commonly, each fiber leaving the
central office is actually shared by many homes; it is not until the fiber gets relatively close to the homes that it is split into individual customer-specific fibers.
There are two competing optical-distribution network architectures that perform

15

16

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

Internet

Central office

ONT

Optical
splitter

ONT

OLT
ONT

Optical
fibers

Figure 1.7 ♦ FTTH Internet access
this splitting: active optical networks (AONs) and passive optical networks (PONs).
AON is essentially switched Ethernet, which is discussed in Chapter 6.
Here, we briefly discuss PON, which is used in Verizon’s FiOS service.
Figure 1.7 shows FTTH using the PON distribution architecture. Each home has
an optical network terminator (ONT), which is connected by dedicated optical
fiber to a neighborhood splitter. The splitter combines a number of homes (typically less than 100) onto a single, shared optical fiber, which connects to an optical
line terminator (OLT) in the telco’s CO. The OLT, providing conversion between
optical and electrical signals, connects to the Internet via a telco router. At home,
users connect a home router (typically a wireless router) to the ONT and access the
Internet via this home router. In the PON architecture, all packets sent from OLT to
the splitter are replicated at the splitter (similar to a cable head end).
In addition to DSL, Cable, and FTTH, 5G fixed wireless is beginning to be
deployed. 5G fixed wireless not only promises high-speed residential access, but
will do so without installing costly and failure-prone cabling from the telco’s
CO to the home. With 5G fixed wireless, using beam-forming technology, data
is sent wirelessly from a provider’s base station to the a modem in the home.
A WiFi wireless router is connected to the modem (possibly bundled together),
similar to how a WiFi wireless router is connected to a cable or DSL modem.
5G cellular networks are covered in Chapter 7.

Access in the Enterprise (and the Home): Ethernet and WiFi
On corporate and university campuses, and increasingly in home settings, a local
area!network (LAN) is used to connect an end system to the edge router. Although
there are many types of LAN technologies, Ethernet is by far the most prevalent access technology in corporate, university, and home networks. As shown in

1.2

•

THE NETWORK EDGE

1 Gbps
1 Gbps

Ethernet
switch

Institutional
router
To Institution’s
ISP

1 Gbps

Server

Figure 1.8 ♦ Ethernet Internet access
Figure 1.8, Ethernet users use twisted-pair copper wire to connect to an Ethernet
switch, a! technology discussed in detail in Chapter 6. The Ethernet switch, or a
network of such interconnected switches, is then in turn connected into the larger
Internet. With Ethernet access, users typically have 100 Mbps to tens of Gbps
access to the Ethernet switch, whereas servers may have 1 Gbps 10 Gbps access.
Increasingly, however, people are accessing the Internet wirelessly from laptops, smartphones, tablets, and other “things”. In a wireless LAN setting, wireless
users transmit/receive packets to/from an access point that is connected into the
enterprise’s network (most likely using wired Ethernet), which in turn is connected
to the wired Internet. A wireless LAN user must typically be within a few tens of
meters of the access point. Wireless LAN access based on IEEE 802.11 technology, more colloquially known as WiFi, is now just about everywhere—universities,
business offices, cafes, airports, homes, and even in airplanes. As discussed in detail
in Chapter 7, 802.11 today provides a shared transmission rate of up to more than
100 Mbps.
Even though Ethernet and WiFi access networks were initially deployed in
enterprise (corporate, university) settings, they are also common components of
home networks. Many homes combine broadband residential access (that is, cable
modems or DSL) with these inexpensive wireless LAN technologies to create powerful home networks Figure 1.9 shows a typical home network. This home network
consists of a roaming laptop, multiple Internet-connected home appliances, as well
as a wired PC; a base station (the wireless access point), which communicates with
the wireless PC and other wireless devices in the home; and a home router that connects the wireless access point, and any other wired home devices, to the Internet.
This network allows household members to have broadband access to the Internet
with one member roaming from the kitchen to the backyard to the bedrooms.

17

18

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

Cable
head end

Internet

Home Network

Figure 1.9 ♦ A typical home network

Wide-Area Wireless Access: 3G and LTE 4G and 5G
Mobile devices such as iPhones and Android devices are being used to message, share
photos in social networks, make mobile payments, watch movies, stream music, and
much more while on the run. These devices employ the same wireless infrastructure
used for cellular telephony to send/receive packets through a base station that is operated by the cellular network provider. Unlike WiFi, a user need only be within a few
tens of kilometers (as opposed to a few tens of meters) of the base station.
Telecommunications companies have made enormous investments in so-called
fourth-generation (4G) wireless, which provides real-world download speeds of up to
60 Mbps. But even higher-speed wide-area access technologies—a fifth-generation
(5G) of wide-area wireless networks—are already being deployed. We’ll cover the
basic principles of wireless networks and mobility, as well as WiFi, 4G and 5G technologies (and more!) in Chapter 7.

1.2.2 Physical Media
In the previous subsection, we gave an overview of some of the most important
network access technologies in the Internet. As we described these technologies,
we also indicated the physical media used. For example, we said that HFC uses a
combination of fiber cable and coaxial cable. We said that DSL and Ethernet use
copper wire. And we said that mobile access networks use the radio spectrum. In this
subsection, we provide a brief overview of these and other transmission media that
are commonly used in the Internet.
In order to define what is meant by a physical medium, let us reflect on the
brief life of a bit. Consider a bit traveling from one end system, through a series
of links and routers, to another end system. This poor bit gets kicked around
and transmitted many, many times! The source end system first transmits the

1.2

•

THE NETWORK EDGE

bit, and shortly thereafter the first router in the series receives the bit; the first
router then transmits the bit, and shortly thereafter the second router receives the
bit; and so on. Thus our bit, when traveling from source to destination, passes
through a series of transmitter-receiver pairs. For each transmitter-receiver pair,
the bit is sent by propagating electromagnetic waves or optical pulses across a
physical medium. The physical medium can take many shapes and forms and
does not have to be of the same type for each transmitter-receiver pair along
the path. Examples of physical media include twisted-pair copper wire, coaxial
cable, multimode fiber-optic cable, terrestrial radio spectrum, and satellite radio
spectrum. Physical media fall into two categories: guided media and unguided
media. With guided media, the waves are guided along a solid medium, such as
a fiber-optic cable, a twisted-pair copper wire, or a coaxial cable. With unguided
media, the waves propagate in the atmosphere and in outer space, such as in a
wireless LAN or a digital satellite channel.
But before we get into the characteristics of the various media types, let us say a
few words about their costs. The actual cost of the physical link (copper wire, fiberoptic cable, and so on) is often relatively minor compared with other networking
costs. In particular, the labor cost associated with the installation of the physical link
can be orders of magnitude higher than the cost of the material. For this reason, many
builders install twisted pair, optical fiber, and coaxial cable in every room in a building. Even if only one medium is initially used, there is a good chance that another
medium could be used in the near future, and so money is saved by not having to lay
additional wires in the future.

Twisted-Pair Copper Wire
The least expensive and most commonly used guided transmission medium is
twisted-pair copper wire. For over a hundred years it has been used by telephone
networks. In fact, more than 99 percent of the wired connections from the telephone
handset to the local telephone switch use twisted-pair copper wire. Most of us have
seen twisted pair in our homes (or those of our parents or grandparents!) and work
environments. Twisted pair consists of two insulated copper wires, each about 1 mm
thick, arranged in a regular spiral pattern. The wires are twisted together to reduce the
electrical interference from similar pairs close by. Typically, a number of pairs are
bundled together in a cable by wrapping the pairs in a protective shield. A wire pair
constitutes a single communication link. Unshielded twisted pair (UTP) is commonly used for computer networks within a building, that is, for LANs. Data rates
for LANs using twisted pair today range from 10 Mbps to 10 Gbps. The data rates
that can be achieved depend on the thickness of the wire and the distance between
transmitter and receiver.
When fiber-optic technology emerged in the 1980s, many people disparaged twisted pair because of its relatively low bit rates. Some people even felt

19

20

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

that fiber-optic technology would completely replace twisted pair. But twisted
pair did not give up so easily. Modern twisted-pair technology, such as category
6a cable, can achieve data rates of 10 Gbps for distances up to a hundred meters.
In the end, twisted pair has emerged as the dominant solution for high-speed
LAN networking.
As discussed earlier, twisted pair is also commonly used for residential Internet access. We saw that dial-up modem technology enables access at rates of up to
56!kbps over twisted pair. We also saw that DSL (digital subscriber line) technology
has enabled residential users to access the Internet at tens of Mbps over twisted pair
(when users live close to the ISP’s central office).

Coaxial Cable
Like twisted pair, coaxial cable consists of two copper conductors, but the two conductors are concentric rather than parallel. With this construction and special insulation and shielding, coaxial cable can achieve high data transmission rates. Coaxial
cable is quite common in cable television systems. As we saw earlier, cable television systems have recently been coupled with cable modems to provide residential
users with Internet access at rates of hundreds of Mbps. In cable television and cable
Internet access, the transmitter shifts the digital signal to a specific frequency band,
and the resulting analog signal is sent from the transmitter to one or more receivers.
Coaxial cable can be used as a guided shared medium. Specifically, a number of
end systems can be connected directly to the cable, with each of the end systems
receiving whatever is sent by the other end systems.

Fiber Optics
An optical fiber is a thin, flexible medium that conducts pulses of light, with each
pulse representing a bit. A single optical fiber can support tremendous bit rates, up
to tens or even hundreds of gigabits per second. They are immune to electromagnetic
interference, have very low signal attenuation up to 100 kilometers, and are very hard
to tap. These characteristics have made fiber optics the preferred long-haul guided
transmission media, particularly for overseas links. Many of the long-distance telephone networks in the United States and elsewhere now use fiber optics exclusively.
Fiber optics is also prevalent in the backbone of the Internet. However, the high cost
of optical devices—such as transmitters, receivers, and switches—has hindered their
deployment for short-haul transport, such as in a LAN or into the home in a residential access network. The Optical Carrier (OC) standard link speeds range from
51.8!Mbps to 39.8 Gbps; these specifications are often referred to as OC-n, where
the link speed equals n × 51.8 Mbps. Standards in use today include OC-1, OC-3,
OC-12, OC-24, OC-48, OC-96, OC-192, OC-768.

1.2

•

THE NETWORK EDGE

Terrestrial Radio Channels
Radio channels carry signals in the electromagnetic spectrum. They are an attractive medium because they require no physical wire to be installed, can penetrate
walls, provide connectivity to a mobile user, and can potentially carry a signal
for long distances. The characteristics of a radio channel depend significantly
on the propagation environment and the distance over which a signal is to be
carried. Environmental considerations determine path loss and shadow fading (which decrease the signal strength as the signal travels over a distance and
around/through obstructing objects), multipath fading (due to signal reflection off
of interfering objects), and interference (due to other transmissions and electromagnetic signals).
Terrestrial radio channels can be broadly classified into three groups: those that
operate over very short distance (e.g., with one or two meters); those that operate in
local areas, typically spanning from ten to a few hundred meters; and those that operate in the wide area, spanning tens of kilometers. Personal devices such as wireless
headsets, keyboards, and medical devices operate over short distances; the wireless
LAN technologies described in Section 1.2.1 use local-area radio channels; the cellular access technologies use wide-area radio channels. We’ll discuss radio channels
in detail in Chapter 7.

Satellite Radio Channels
A communication satellite links two or more Earth-based microwave transmitter/
receivers, known as ground stations. The satellite receives transmissions on
one frequency band, regenerates the signal using a repeater (discussed below),
and transmits the signal on another frequency. Two types of satellites are used
in! communications: geostationary satellites and low-earth orbiting (LEO)
satellites.
Geostationary satellites permanently remain above the same spot on Earth.
This stationary presence is achieved by placing the satellite in orbit at 36,000 kilometers above Earth’s surface. This huge distance from ground station through
satellite back to ground station introduces a substantial signal propagation delay
of 280 milliseconds. Nevertheless, satellite links, which can operate at speeds of
hundreds of Mbps, are often used in areas without access to DSL or cable-based
Internet access.
LEO satellites are placed much closer to Earth and do not remain permanently
above one spot on Earth. They rotate around Earth (just as the Moon does) and may
communicate with each other, as well as with ground stations. To provide continuous
coverage to an area, many satellites need to be placed in orbit. There are currently
many low-altitude communication systems in development. LEO satellite technology
may be used for Internet access sometime in the future.

21

22

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

1.3 The Network Core
Having examined the Internet’s edge, let us now delve more deeply inside the
network core—the mesh of packet switches and links that interconnects the
Internet’s end systems. Figure 1.10 highlights the network core with thick,
shaded lines.

National or
Global ISP

Mobile Network
Datacenter Network

Datacenter Network

Home Network

Local or
Regional ISP

Enterprise Network

Figure 1.10 ♦ The network core

Content Provider Network

1.3

•

THE NETWORK CORE

1.3.1 Packet Switching
In a network application, end systems exchange messages with each other. Messages can contain anything the application designer wants. Messages may perform
a control function (for example, the “Hi” messages in our handshaking example in
Figure 1.2) or can contain data, such as an e-mail message, a JPEG image, or an
MP3 audio file. To send a message from a source end system to a destination end
system, the source breaks long messages into smaller chunks of data known as packets. Between source and destination, each packet travels through communication
links and packet switches (for which there are two predominant types, routers and
link-layer switches). Packets are transmitted over each communication link at a rate
equal to the full transmission rate of the link. So, if a source end system or a packet
switch is sending a packet of L bits over a link with transmission rate R bits/sec, then
the time to transmit the packet is L /R seconds.

Store-and-Forward Transmission
Most packet switches use store-and-forward transmission at the inputs to the
links. Store-and-forward transmission means that the packet switch must receive
the entire packet before it can begin to transmit the first bit of the packet onto the
outbound link. To explore store-and-forward transmission in more detail, consider
a simple network consisting of two end systems connected by a single router, as
shown in Figure 1.11. A router will typically have many incident links, since its
job is to switch an incoming packet onto an outgoing link; in this simple example,
the router has the rather simple task of transferring a packet from one (input) link
to the only other attached link. In this example, the source has three packets, each
consisting of L bits, to send to the destination. At the snapshot of time shown in
Figure 1.11, the source has transmitted some of packet 1, and the front of packet 1
has already arrived at the router. Because the router employs store-and-forwarding,
at this instant of time, the router cannot transmit the bits it has received; instead it
must first buffer (i.e., “store”) the packet’s bits. Only after the router has received
all of the packet’s bits can it begin to transmit (i.e., “forward”) the packet onto the
outbound link. To gain some insight into store-and-forward transmission, let’s now
calculate the amount of time that elapses from when the source begins to send the
packet until the destination has received the entire packet. (Here we will ignore
propagation delay—the time it takes for the bits to travel across the wire at near
the speed of light—which will be discussed in Section 1.4.) The source begins to
transmit at time 0; at time L/R seconds, the source has transmitted the entire packet,
and the entire packet has been received and stored at the router (since there is no
propagation delay). At time L/R seconds, since the router has just received the entire
packet, it can begin to transmit the packet onto the outbound link towards the destination; at time 2L/R, the router has transmitted the entire packet, and the entire
packet has been received by the destination. Thus, the total delay is 2L/R. If the

23

24

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

321

Source

R bps

Front of packet 1
stored in router,
awaiting remaining
bits before forwarding

Destination

Figure 1.11 ♦ Store-and-forward packet switching
switch instead forwarded bits as soon as they arrive (without first receiving the entire
packet), then the total delay would be L/R since bits are not held up at the router.
But, as we will discuss in Section 1.4, routers need to receive, store, and process the
entire packet before forwarding.
Now let’s calculate the amount of time that elapses from when the source begins
to send the first packet until the destination has received all three packets. As before,
at time L/R, the router begins to forward the first packet. But also at time L/R the
source will begin to send the second packet, since it has just finished sending the
entire first packet. Thus, at time 2L/R, the destination has received the first packet
and the router has received the second packet. Similarly, at time 3L/R, the destination has received the first two packets and the router has received the third packet.
Finally, at time 4L/R the destination has received all three packets!
Let’s now consider the general case of sending one packet from source to destination over a path consisting of N links each of rate R (thus, there are N-1 routers
between source and destination). Applying the same logic as above, we see that the
end-to-end delay is:
dend@to@end = N

L
R

(1.1)

You may now want to try to determine what the delay would be for P packets sent
over a series of N links.

Queuing Delays and Packet Loss
Each packet switch has multiple links attached to it. For each attached link, the
packet switch has an output buffer (also called an output queue), which stores
packets that the router is about to send into that link. The output buffers play a key
role in packet switching. If an arriving packet needs to be transmitted onto a link but
finds the link busy with the transmission of another packet, the arriving packet must
wait in the output buffer. Thus, in addition to the store-and-forward delays, packets
suffer output buffer queuing delays. These delays are variable and depend on the

1.3

•

THE NETWORK CORE

100 Mbps Ethernet

C

A
15 Mbps
Queue of
packets waiting
for output link
B

Key:

D

E

Packets

Figure 1.12 ♦ Packet switching

level of congestion in the network. Since the amount of buffer space is finite, an
arriving packet may find that the buffer is completely full with other packets waiting
for transmission. In this case, packet loss will occur—either the arriving packet or
one of the already-queued packets will be dropped.
Figure 1.12 illustrates a simple packet-switched network. As in Figure 1.11,
packets are represented by three-dimensional slabs. The width of a slab represents
the number of bits in the packet. In this figure, all packets have the same width and
hence the same length. Suppose Hosts A and B are sending packets to Host E. Hosts
A and B first send their packets along 100 Mbps Ethernet links to the first router.
The router then directs these packets to the 15 Mbps link. If, during a short interval
of time, the arrival rate of packets to the router (when converted to bits per second)
exceeds 15 Mbps, congestion will occur at the router as packets queue in the link’s
output buffer before being transmitted onto the link. For example, if Host A and B
each send a burst of five packets back-to-back at the same time, then most of these
packets will spend some time waiting in the queue. The situation is, in fact, entirely
analogous to many common-day situations—for example, when we wait in line for a
bank teller or wait in front of a tollbooth. We’ll examine this queuing delay in more
detail in Section 1.4.

Forwarding Tables and Routing Protocols
Earlier, we said that a router takes a packet arriving on one of its attached communication links and forwards that packet onto another one of its attached
communication links. But how does the router determine which link it should

25

26

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

forward the packet onto? Packet forwarding is actually done in different ways in
different types of computer networks. Here, we briefly describe how it is done
in the Internet.
In the Internet, every end system has an address called an IP address. When
a source end system wants to send a packet to a destination end system, the
source includes the destination’s IP address in the packet’s header. As with postal
addresses, this address has a hierarchical structure. When a packet arrives at a router
in the network, the router examines a portion of the packet’s destination address
and forwards the packet to an adjacent router. More specifically, each router has
a forwarding table that maps destination addresses (or portions of the destination
addresses) to that router’s outbound links. When a packet arrives at a router, the
router examines the address and searches its forwarding table, using this destination
address, to find the appropriate outbound link. The router then directs the packet to
this outbound link.
The end-to-end routing process is analogous to a car driver who does not
use maps but instead prefers to ask for directions. For example, suppose Joe is
driving from Philadelphia to 156 Lakeside Drive in Orlando, Florida. Joe first
drives to his neighborhood gas station and asks how to get to 156 Lakeside Drive
in Orlando, Florida. The gas station attendant extracts the Florida portion of the
address and tells Joe that he needs to get onto the interstate highway I-95 South,
which has an entrance just next to the gas station. He also tells Joe that once he
enters Florida, he should ask someone else there. Joe then takes I-95 South until he
gets to Jacksonville, Florida, at which point he asks another gas station attendant
for directions. The attendant extracts the Orlando portion of the address and tells
Joe that he should continue on I-95 to Daytona Beach and then ask someone else.
In Daytona Beach, another gas station attendant also extracts the Orlando portion
of the address and tells Joe that he should take I-4 directly to Orlando. Joe takes
I-4 and gets off at the Orlando exit. Joe goes to another gas station attendant, and
this time the attendant extracts the Lakeside Drive portion of the address and tells
Joe the road he must follow to get to Lakeside Drive. Once Joe reaches Lakeside
Drive, he asks a kid on a bicycle how to get to his destination. The kid extracts the
156 portion of the address and points to the house. Joe finally reaches his ultimate
destination. In the above analogy, the gas station attendants and kids on bicycles
are analogous to routers.
We just learned that a router uses a packet’s destination address to index a forwarding table and determine the appropriate outbound link. But this statement begs
yet another question: How do forwarding tables get set? Are they configured by hand
in each and every router, or does the Internet use a more automated procedure? This
issue will be studied in depth in Chapter 5. But to whet your appetite here, we’ll note
now that the Internet has a number of special routing protocols that are used to automatically set the forwarding tables. A routing protocol may, for example, determine
the shortest path from each router to each destination and use the shortest path results
to configure the forwarding tables in the routers.

1.3

•

THE NETWORK CORE

1.3.2 Circuit Switching
There are two fundamental approaches to moving data through a network of links
and switches: circuit switching and packet switching. Having covered packetswitched networks in the previous subsection, we now turn our attention to circuitswitched networks.
In circuit-switched networks, the resources needed along a path (buffers, link
transmission rate) to provide for communication between the end systems are
reserved for the duration of the communication session between the end systems.
In packet-switched networks, these resources are not reserved; a session’s messages
use the resources on demand and, as a consequence, may have to wait (that is, queue)
for access to a communication link. As a simple analogy, consider two restaurants,
one that requires reservations and another that neither requires reservations nor
accepts them. For the restaurant that requires reservations, we have to go through
the hassle of calling before we leave home. But when we arrive at the restaurant we
can, in principle, immediately be seated and order our meal. For the restaurant that
does not require reservations, we don’t need to bother to reserve a table. But when
we arrive at the restaurant, we may have to wait for a table before we can be seated.
Traditional telephone networks are examples of circuit-switched networks.
Consider what happens when one person wants to send information (voice or facsimile)
to another over a telephone network. Before the sender can send the information,
the network must establish a connection between the sender and the receiver. This
is a bona fide connection for which the switches on the path between the sender and
receiver maintain connection state for that connection. In the jargon of telephony,
this connection is called a circuit. When the network establishes the circuit, it also
reserves a constant transmission rate in the network’s links (representing a fraction
of each link’s transmission capacity) for the duration of the connection. Since a given
transmission rate has been reserved for this sender-to-receiver connection, the sender
can transfer the data to the receiver at the guaranteed constant rate.
Figure 1.13 illustrates a circuit-switched network. In this network, the four
circuit switches are interconnected by four links. Each of these links has four circuits, so that each link can support four simultaneous connections. The hosts (for
example, PCs and workstations) are each directly connected to one of the switches.
When two hosts want to communicate, the network establishes a dedicated endto-end connection between the two hosts. Thus, in order for Host A to communicate with Host B, the network must first reserve one circuit on each of two links.
In this example, the dedicated end-to-end connection uses the second circuit in
the first link and the fourth circuit in the second link. Because each link has four
circuits, for each link used by the end-to-end connection, the connection gets one
fourth of the link’s total transmission capacity for the duration of the connection.
Thus, for example, if each link between adjacent switches has a transmission rate of
1 Mbps, then each end-to-end circuit-switch connection gets 250 kbps of dedicated
transmission rate.

27

28

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

Figure 1.13 ♦ A simple circuit-switched network consisting of four switches
and four links
In contrast, consider what happens when one host wants to send a packet to
another host over a packet-switched network, such as the Internet. As with circuit
switching, the packet is transmitted over a series of communication links. But different from circuit switching, the packet is sent into the network without reserving
any link resources whatsoever. If one of the links is congested because other packets
need to be transmitted over the link at the same time, then the packet will have to
wait in a buffer at the sending side of the transmission link and suffer a delay. The
Internet makes its best effort to deliver packets in a timely manner, but it does not
make any guarantees.

Multiplexing in Circuit-Switched Networks
A circuit in a link is implemented with either frequency-division multiplexing
(FDM) or time-division multiplexing (TDM). With FDM, the frequency spectrum
of a link is divided up among the connections established across the link. Specifically, the link dedicates a frequency band to each connection for the duration of the
connection. In telephone networks, this frequency band typically has a width of
4! kHz (that is, 4,000 hertz or 4,000 cycles per second). The width of the band is
called, not surprisingly, the bandwidth. FM radio stations also use FDM to share
the frequency spectrum between 88 MHz and 108 MHz, with each station being
allocated a specific frequency band.
For a TDM link, time is divided into frames of fixed duration, and each frame is
divided into a fixed number of time slots. When the network establishes a connection
across a link, the network dedicates one time slot in every frame to this connection.
These slots are dedicated for the sole use of that connection, with one time slot available for use (in every frame) to transmit the connection’s data.

1.3

•

THE NETWORK CORE

FDM
4KHz
Link

Frequency

4KHz

TDM
1 2
Slot

3

4 1 2

3

4

1 2

3

4 1 2

3

4

Frame
Time

Key:
2

All slots labeled “2” are dedicated
to a specific sender-receiver pair.

Figure 1.14 ♦ With FDM, each circuit continuously gets a fraction of the
bandwidth. With TDM, each circuit gets all of the bandwidth
periodically during brief intervals of time (that is, during slots)
Figure 1.14 illustrates FDM and TDM for a specific network link supporting
up to four circuits. For FDM, the frequency domain is segmented into four bands,
each of bandwidth 4 kHz. For TDM, the time domain is segmented into frames, with
four time slots in each frame; each circuit is assigned the same dedicated slot in the
revolving TDM frames. For TDM, the transmission rate of a circuit is equal to the
frame rate multiplied by the number of bits in a slot. For example, if the link transmits 8,000 frames per second and each slot consists of 8 bits, then the transmission
rate of each circuit is 64 kbps.
Proponents of packet switching have always argued that circuit switching is wasteful because the dedicated circuits are idle during silent periods. For example, when one
person in a telephone call stops talking, the idle network resources (frequency bands or
time slots in the links along the connection’s route) cannot be used by other ongoing
connections. As another example of how these resources can be underutilized, consider
a radiologist who uses a circuit-switched network to remotely access a series of x-rays.
The radiologist sets up a connection, requests an image, contemplates the image, and
then requests a new image. Network resources are allocated to the connection but are
not used (i.e., are wasted) during the radiologist’s contemplation periods. Proponents
of packet switching also enjoy pointing out that establishing end-to-end circuits and
reserving end-to-end transmission capacity is complicated and requires complex signaling software to coordinate the operation of the switches along the end-to-end path.

29

30

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

Before we finish our discussion of circuit switching, let’s work through a numerical example that should shed further insight on the topic. Let us consider how long
it takes to send a file of 640,000 bits from Host A to Host B over a circuit-switched
network. Suppose that all links in the network use TDM with 24 slots and have a bit
rate of 1.536 Mbps. Also suppose that it takes 500 msec to establish an end-to-end
circuit before Host A can begin to transmit the file. How long does it take to send
the file? Each circuit has a transmission rate of (1.536 Mbps)/24 = 64 kbps, so it
takes (640,000 bits)/(64 kbps) = 10 seconds to transmit the file. To this 10 seconds
we add the circuit establishment time, giving 10.5 seconds to send the file. Note
that the transmission time is independent of the number of links: The transmission
time would be 10 seconds if the end-to-end circuit passed through one link or a
hundred links. (The actual end-to-end delay also includes a propagation delay; see
Section 1.4.)

Packet Switching Versus Circuit Switching
Having described circuit switching and packet switching, let us compare the two.
Critics of packet switching have often argued that packet switching is not suitable for real-time services (for example, telephone calls and video conference calls)
because of its variable and unpredictable end-to-end delays (due primarily to variable and unpredictable queuing delays). Proponents of packet switching argue that
(1) it offers better sharing of transmission capacity than circuit switching and (2) it
is simpler, more efficient, and less costly to implement than circuit switching. An
interesting discussion of packet switching versus circuit switching is [MolineroFernandez 2002]. Generally speaking, people who do not like to hassle with restaurant
reservations prefer packet switching to circuit switching.
Why is packet switching more efficient? Let’s look at a simple example. Suppose users share a 1 Mbps link. Also suppose that each user alternates between periods of activity, when a user generates data at a constant rate of 100 kbps, and periods
of inactivity, when a user generates no data. Suppose further that a user is active only
10 percent of the time (and is idly drinking coffee during the remaining 90 percent
of the time). With circuit switching, 100 kbps must be reserved for each user at all
times. For example, with circuit-switched TDM, if a one-second frame is divided
into 10 time slots of 100 ms each, then each user would be allocated one time slot
per frame.
Thus, the circuit-switched link can support only 10 ( = 1 Mbps/100 kbps) simultaneous users. With packet switching, the probability that a specific user is active
is 0.1 (that is, 10 percent). If there are 35 users, the probability that there are 11 or
more simultaneously active users is approximately 0.0004. (Homework Problem P8
outlines how this probability is obtained.) When there are 10 or fewer simultaneously active users (which happens with probability 0.9996), the aggregate arrival
rate of data is less than or equal to 1 Mbps, the output rate of the link. Thus, when
there are 10 or fewer active users, users’ packets flow through the link essentially

1.3

•

THE NETWORK CORE

without delay, as is the case with circuit switching. When there are more than 10
simultaneously active users, then the aggregate arrival rate of packets exceeds the
output capacity of the link, and the output queue will begin to grow. (It continues to
grow until the aggregate input rate falls back below 1 Mbps, at which point the queue
will begin to diminish in length.) Because the probability of having more than 10
simultaneously active users is minuscule in this example, packet switching provides
essentially the same performance as circuit switching, but does so while allowing for
more than three times the number of users.
Let’s now consider a second simple example. Suppose there are 10 users and
that one user suddenly generates one thousand 1,000-bit packets, while other users
remain quiescent and do not generate packets. Under TDM circuit switching with 10
slots per frame and each slot consisting of 1,000 bits, the active user can only use its
one time slot per frame to transmit data, while the remaining nine time slots in each
frame remain idle. It will be 10 seconds before all of the active user’s one million
bits of data has been transmitted. In the case of packet switching, the active user can
continuously send its packets at the full link rate of 1 Mbps, since there are no other
users generating packets that need to be multiplexed with the active user’s packets.
In this case, all of the active user’s data will be transmitted within 1 second.
The above examples illustrate two ways in which the performance of packet
switching can be superior to that of circuit switching. They also highlight the crucial difference between the two forms of sharing a link’s transmission rate among
multiple data streams. Circuit switching pre-allocates use of the transmission link
regardless of demand, with allocated but unneeded link time going unused. Packet
switching on the other hand allocates link use on demand. Link transmission capacity
will be shared on a packet-by-packet basis only among those users who have packets
that need to be transmitted over the link.
Although packet switching and circuit switching are both prevalent in today’s
telecommunication networks, the trend has certainly been in the direction of packet
switching. Even many of today’s circuit-switched telephone networks are slowly
migrating toward packet switching. In particular, telephone networks often use
packet switching for the expensive overseas portion of a telephone call.

1.3.3 A Network of Networks
We saw earlier that end systems (PCs, smartphones, Web servers, mail servers, and
so on) connect into the Internet via an access ISP. The access ISP can provide either
wired or wireless connectivity, using an array of access technologies including DSL,
cable, FTTH, Wi-Fi, and cellular. Note that the access ISP does not have to be a
telco or a cable company; instead it can be, for example, a university (providing
Internet access to students, staff, and faculty), or a company (providing access for
its employees). But connecting end users and content providers into an access ISP is
only a small piece of solving the puzzle of connecting the billions of end systems that
make up the Internet. To complete this puzzle, the access ISPs themselves must be

31

32

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

interconnected. This is done by creating a network of networks—understanding this
phrase is the key to understanding the Internet.
Over the years, the network of networks that forms the Internet has evolved into
a very complex structure. Much of this evolution is driven by economics and national
policy, rather than by performance considerations. In order to understand today’s
Internet network structure, let’s incrementally build a series of network structures,
with each new structure being a better approximation of the complex Internet that we
have today. Recall that the overarching goal is to interconnect the access ISPs so that
all end systems can send packets to each other. One naive approach would be to have
each access ISP directly connect with every other access ISP. Such a mesh design is,
of course, much too costly for the access ISPs, as it would require each access ISP
to have a separate communication link to each of the hundreds of thousands of other
access ISPs all over the world.
Our first network structure, Network Structure 1, interconnects all of the access
ISPs with a single global transit ISP. Our (imaginary) global transit ISP is a network
of routers and communication links that not only spans the globe, but also has at least
one router near each of the hundreds of thousands of access ISPs. Of course, it would
be very costly for the global ISP to build such an extensive network. To be profitable,
it would naturally charge each of the access ISPs for connectivity, with the pricing
reflecting (but not necessarily directly proportional to) the amount of traffic an access
ISP exchanges with the global ISP. Since the access ISP pays the global transit ISP, the
access ISP is said to be a customer and the global transit ISP is said to be a provider.
Now if some company builds and operates a global transit ISP that is profitable, then it is natural for other companies to build their own global transit ISPs
and compete with the original global transit ISP. This leads to Network Structure 2,
which consists of the hundreds of thousands of access ISPs and multiple global
transit ISPs. The access ISPs certainly prefer Network Structure 2 over Network
Structure 1 since they can now choose among the competing global transit providers
as a function of their pricing and services. Note, however, that the global transit ISPs
themselves must interconnect: Otherwise access ISPs connected to one of the global
transit providers would not be able to communicate with access ISPs connected to the
other global transit providers.
Network Structure 2, just described, is a two-tier hierarchy with global transit
providers residing at the top tier and access ISPs at the bottom tier. This assumes
that global transit ISPs are not only capable of getting close to each and every access
ISP, but also find it economically desirable to do so. In reality, although some ISPs
do have impressive global coverage and do directly connect with many access ISPs,
no ISP has presence in each and every city in the world. Instead, in any given region,
there may be a regional ISP to which the access ISPs in the region connect. Each
regional ISP then connects to tier-1 ISPs. Tier-1 ISPs are similar to our (imaginary)
global transit ISP; but tier-1 ISPs, which actually do exist, do not have a presence
in every city in the world. There are approximately a dozen tier-1 ISPs, including
Level 3 Communications, AT&T, Sprint, and NTT. Interestingly, no group officially

1.3

•

THE NETWORK CORE

sanctions tier-1 status; as the saying goes—if you have to ask if you’re a member of
a group, you’re probably not.
Returning to this network of networks, not only are there multiple competing
tier-1 ISPs, there may be multiple competing regional ISPs in a region. In such a
hierarchy, each access ISP pays the regional ISP to which it connects, and each
regional ISP pays the tier-1 ISP to which it connects. (An access ISP can also connect
directly to a tier-1 ISP, in which case it pays the tier-1 ISP). Thus, there is customerprovider relationship at each level of the hierarchy. Note that the tier-1 ISPs do not
pay anyone as they are at the top of the hierarchy. To further complicate matters, in
some regions, there may be a larger regional ISP (possibly spanning an entire country) to which the smaller regional ISPs in that region connect; the larger regional
ISP then connects to a tier-1 ISP. For example, in China, there are access ISPs in
each city, which connect to provincial ISPs, which in turn connect to national ISPs,
which finally connect to tier-1 ISPs [Tian 2012]. We refer to this multi-tier hierarchy,
which is still only a crude approximation of today’s Internet, as Network Structure 3.
To build a network that more closely resembles today’s Internet, we must add
points of presence (PoPs), multi-homing, peering, and Internet exchange points
(IXPs) to the hierarchical Network Structure 3. PoPs exist in all levels of the hierarchy, except for the bottom (access ISP) level. A PoP is simply a group of one or
more routers (at the same location) in the provider’s network where customer ISPs
can connect into the provider ISP. For a customer network to connect to a provider’s
PoP, it can lease a high-speed link from a third-party telecommunications provider
to directly connect one of its routers to a router at the PoP. Any ISP (except for tier-1
ISPs) may choose to multi-home, that is, to connect to two or more provider ISPs. So,
for example, an access ISP may multi-home with two regional ISPs, or it may multihome with two regional ISPs and also with a tier-1 ISP. Similarly, a regional ISP may
multi-home with multiple tier-1 ISPs. When an ISP multi-homes, it can continue to
send and receive packets into the Internet even if one of its providers has a failure.
As we just learned, customer ISPs pay their provider ISPs to obtain global Internet interconnectivity. The amount that a customer ISP pays a provider ISP reflects
the amount of traffic it exchanges with the provider. To reduce these costs, a pair
of nearby ISPs at the same level of the hierarchy can peer, that is, they can directly
connect their networks together so that all the traffic between them passes over the
direct connection rather than through upstream intermediaries. When two ISPs peer,
it is typically settlement-free, that is, neither ISP pays the other. As noted earlier,
tier-1 ISPs also peer with one another, settlement-free. For a readable discussion of
peering and customer-provider relationships, see [Van der Berg 2008]. Along these
same lines, a third-party company can create an Internet Exchange Point (IXP),
which is a meeting point where multiple ISPs can peer together. An IXP is typically
in a stand-alone building with its own switches [Ager 2012]. There are over 600 IXPs
in the Internet today [PeeringDB 2020]. We refer to this ecosystem—consisting of
access ISPs, regional ISPs, tier-1 ISPs, PoPs, multi-homing, peering, and IXPs—as
Network Structure 4.

33

34

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

We now finally arrive at Network Structure 5, which describes today’s Internet.
Network Structure 5, illustrated in Figure 1.15, builds on top of Network Structure 4
by adding content-provider networks. Google is currently one of the leading examples of such a content-provider network. As of this writing, it Google has 19 major data
centers distributed across North America, Europe, Asia, South America, and Australia
with each data center having tens or hundreds of thousands of servers. Additionally,
Google has smaller data centers, each with a few hundred servers; these smaller data
centers are often located within IXPs. The Google data centers are all interconnected
via Google’s private TCP/IP network, which spans the entire globe but is nevertheless separate from the public Internet. Importantly, the Google private network only
carries traffic to/from Google servers. As shown in Figure 1.15, the Google private
network attempts to “bypass” the upper tiers of the Internet by peering (settlement
free) with lower-tier ISPs, either by directly connecting with them or by connecting
with them at IXPs [Labovitz 2010]. However, because many access ISPs can still only
be reached by transiting through tier-1 networks, the Google network also connects
to tier-1 ISPs, and pays those ISPs for the traffic it exchanges with them. By creating
its own network, a content provider not only reduces its payments to upper-tier ISPs,
but also has greater control of how its services are ultimately delivered to end users.
Google’s network infrastructure is described in greater detail in Section 2.6.
In summary, today’s Internet—a network of networks—is complex, consisting
of a dozen or so tier-1 ISPs and hundreds of thousands of lower-tier ISPs. The ISPs
are diverse in their coverage, with some spanning multiple continents and oceans,
and others limited to narrow geographic regions. The lower-tier ISPs connect to the
higher-tier ISPs, and the higher-tier ISPs interconnect with one another. Users and
content providers are customers of lower-tier ISPs, and lower-tier ISPs are customers
of higher-tier ISPs. In recent years, major content providers have also created their
own networks and connect directly into lower-tier ISPs where possible.

Tier 1
ISP

Content provider
(e.g., Google)

Tier 1
ISP
IXP

IXP
Regional
ISP

access
ISP

access
ISP

access
ISP

IXP
Regional
ISP

access
ISP

Figure 1.15 ♦ Interconnection of ISPs

access
ISP

access
ISP

access
ISP

access
ISP

1.4

•

DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS

1.4 Delay, Loss, and Throughput

in Packet-Switched Networks

Back in Section 1.1 we said that the Internet can be viewed as an infrastructure that
provides services to distributed applications running on end systems. Ideally, we
would like Internet services to be able to move as much data as we want between any
two end systems, instantaneously, without any loss of data. Alas, this is a lofty goal,
one that is unachievable in reality. Instead, computer networks necessarily constrain
throughput (the amount of data per second that can be transferred) between end systems, introduce delays between end systems, and can actually lose packets. On one
hand, it is unfortunate that the physical laws of reality introduce delay and loss as
well as constrain throughput. On the other hand, because computer networks have
these problems, there are many fascinating issues surrounding how to deal with the
problems—more than enough issues to fill a course on computer networking and to
motivate thousands of PhD theses! In this section, we’ll begin to examine and quantify delay, loss, and throughput in computer networks.

1.4.1 Overview of Delay in Packet-Switched Networks
Recall that a packet starts in a host (the source), passes through a series of routers,
and ends its journey in another host (the destination). As a packet travels from one
node (host or router) to the subsequent node (host or router) along this path, the
packet suffers from several types of delays at each node along the path. The most
important of these delays are the nodal processing delay, queuing delay, transmission delay, and propagation delay; together, these delays accumulate to give a total
nodal delay. The performance of many Internet applications—such as search, Web
browsing, e-mail, maps, instant messaging, and voice-over-IP—are greatly affected
by network delays. In order to acquire a deep understanding of packet switching and
computer networks, we must understand the nature and importance of these delays.

Types of Delay
Let’s explore these delays in the context of Figure 1.16. As part of its end-to-end
route between source and destination, a packet is sent from the upstream node
through router A to router B. Our goal is to characterize the nodal delay at router A.
Note that router A has an outbound link leading to router B. This link is preceded
by a queue (also known as a buffer). When the packet arrives at router A from the
upstream node, router A examines the packet’s header to determine the appropriate
outbound link for the packet and then directs the packet to this link. In this example, the outbound link for the packet is the one that leads to router B. A packet can
be transmitted on a link only if there is no other packet currently being transmitted
on the link and if there are no other packets preceding it in the queue; if the link is

35

36

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

A
B

Propagation
Nodal
Queueing Transmission
processing (waiting for
transmission)

Figure 1.16 ♦ The nodal delay at router A
currently busy or if there are other packets already queued for the link, the newly
arriving packet will then join the queue.

Processing Delay
The time required to examine the packet’s header and determine where to direct
the packet is part of the processing delay. The processing delay can also include
other factors, such as the time needed to check for bit-level errors in the packet
that occurred in transmitting the packet’s bits from the upstream node to router A.
Processing delays in high-speed routers are typically on the order of microseconds
or less. After this nodal processing, the router directs the packet to the queue that
precedes the link to router B. (In Chapter 4 we’ll study the details of how a router
operates.)

Queuing Delay
At the queue, the packet experiences a queuing delay as it waits to be transmitted
onto the link. The length of the queuing delay of a specific packet will depend on the
number of earlier-arriving packets that are queued and waiting for transmission onto
the link. If the queue is empty and no other packet is currently being transmitted, then
our packet’s queuing delay will be zero. On the other hand, if the traffic is heavy and
many other packets are also waiting to be transmitted, the queuing delay will be long.
We will see shortly that the number of packets that an arriving packet might expect
to find is a function of the intensity and nature of the traffic arriving at the queue.
Queuing delays can be on the order of microseconds to milliseconds in practice.

Transmission Delay
Assuming that packets are transmitted in a first-come-first-served manner, as is common in packet-switched networks, our packet can be transmitted only after all the
packets that have arrived before it have been transmitted. Denote the length of the

1.4

•

DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS

37

packet by L bits, and denote the transmission rate of the link from router A to router
B by R bits/sec. For example, for a 10 Mbps Ethernet link, the rate is R = 10 Mbps;
for a 100 Mbps Ethernet link, the rate is R = 100 Mbps. The transmission delay is
L/R. This is the amount of time required to push (that is, transmit) all of the packet’s
bits into the link. Transmission delays are typically on the order of microseconds to
milliseconds in practice.

Propagation Delay
Once a bit is pushed into the link, it needs to propagate to router B. The time required
to propagate from the beginning of the link to router B is the propagation delay. The
bit propagates at the propagation speed of the link. The propagation speed depends
on the physical medium of the link (that is, fiber optics, twisted-pair copper wire, and
so on) and is in the range of
2 # 108 meters/sec to 3 # 108 meters/sec
which is equal to, or a little less than, the speed of light. The propagation delay is the
distance between two routers divided by the propagation speed. That is, the propagation delay is d/s, where d is the distance between router A and router B and s is the
propagation speed of the link. Once the last bit of the packet propagates to node B,
it and all the preceding bits of the packet are stored in router B. The whole process
then continues with router B now performing the forwarding. In wide-area networks,
propagation delays are on the order of milliseconds.

Comparing Transmission and Propagation Delay
Newcomers to the field of computer networking sometimes have difficulty understanding the difference between transmission delay and propagation delay. The difference is subtle but important. The transmission delay is the amount of time required
for the router to push out the packet; it is a function of the packet’s length and the
transmission rate of the link, but has nothing to do with the distance between the two
routers. The propagation delay, on the other hand, is the time it takes a bit to propagate from one router to the next; it is a function of the distance between the two routers, but has nothing to do with the packet’s length or the transmission rate of the link.
An analogy might clarify the notions of transmission and propagation delay.
Consider a highway that has a tollbooth every 100 kilometers, as shown in Figure!1.17. You can think of the highway segments between tollbooths as links and
the tollbooths as routers. Suppose that cars travel (that is, propagate) on the highway
at a rate of 100 km/hour (that is, when a car leaves a tollbooth, it instantaneously
accelerates to 100 km/hour and maintains that speed between tollbooths). Suppose
next that 10 cars, traveling together as a caravan, follow each other in a fixed order.
You can think of each car as a bit and the caravan as a packet. Also suppose that each

VideoNote
Exploring propagation
delay and transmission
delay

38

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

100 km

Ten-car
caravan

Toll
booth

100 km

Toll
booth

Figure 1.17 ♦ Caravan analogy
tollbooth services (that is, transmits) a car at a rate of one car per 12 seconds, and that
it is late at night so that the caravan’s cars are the only cars on the highway. Finally,
suppose that whenever the first car of the caravan arrives at a tollbooth, it waits at
the entrance until the other nine cars have arrived and lined up behind it. (Thus, the
entire caravan must be stored at the tollbooth before it can begin to be forwarded.)
The time required for the tollbooth to push the entire caravan onto the highway is
(10 cars)/(5 cars/minute) = 2 minutes. This time is analogous to the transmission
delay in a router. The time required for a car to travel from the exit of one tollbooth
to the next tollbooth is 100 km/(100 km/hour) = 1 hour. This time is analogous to
propagation delay. Therefore, the time from when the caravan is stored in front of a
tollbooth until the caravan is stored in front of the next tollbooth is the sum of transmission delay and propagation delay—in this example, 62 minutes.
Let’s explore this analogy a bit more. What would happen if the tollbooth service time for a caravan were greater than the time for a car to travel between tollbooths? For example, suppose now that the cars travel at the rate of 1,000 km/hour
and the tollbooth services cars at the rate of one car per minute. Then the traveling
delay between two tollbooths is 6 minutes and the time to serve a caravan is 10 minutes. In this case, the first few cars in the caravan will arrive at the second tollbooth
before the last cars in the caravan leave the first tollbooth. This situation also arises
in packet-switched networks—the first bits in a packet can arrive at a router while
many of the remaining bits in the packet are still waiting to be transmitted by the
preceding router.
If a picture speaks a thousand words, then an animation must speak a million
words. The Web site for this textbook provides an interactive animation that nicely
illustrates and contrasts transmission delay and propagation delay. The reader is
highly encouraged to visit that animation. [Smith 2009] also provides a very readable discussion of propagation, queueing, and transmission delays.
If we let dproc, dqueue, dtrans, and dprop denote the processing, queuing, transmission, and propagation delays, then the total nodal delay is given by
dnodal = dproc + dqueue + dtrans + dprop
The contribution of these delay components can vary significantly. For example,
dprop can be negligible (for example, a couple of microseconds) for a link connecting
two routers on the same university campus; however, dprop is hundreds of milliseconds for two routers interconnected by a geostationary satellite link, and can be the

1.4

•

DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS

dominant term in dnodal. Similarly, dtrans can range from negligible to significant. Its
contribution is typically negligible for transmission rates of 10 Mbps and higher (for
example, for LANs); however, it can be hundreds of milliseconds for large Internet
packets sent over low-speed dial-up modem links. The processing delay, dproc, is
often negligible; however, it strongly influences a router’s maximum throughput,
which is the maximum rate at which a router can forward packets.

1.4.2 Queuing Delay and Packet Loss
The most complicated and interesting component of nodal delay is the queuing delay,
dqueue. In fact, queuing delay is so important and interesting in computer networking
that thousands of papers and numerous books have been written about it [Bertsekas
1991; Kleinrock 1975, Kleinrock 1976]. We give only a high-level, intuitive discussion of queuing delay here; the more curious reader may want to browse through
some of the books (or even eventually write a PhD thesis on the subject!). Unlike the
other three delays (namely, dproc, dtrans, and dprop), the queuing delay can vary from
packet to packet. For example, if 10 packets arrive at an empty queue at the same
time, the first packet transmitted will suffer no queuing delay, while the last packet
transmitted will suffer a relatively large queuing delay (while it waits for the other
nine packets to be transmitted). Therefore, when characterizing queuing delay, one
typically uses statistical measures, such as average queuing delay, variance of queuing delay, and the probability that the queuing delay exceeds some specified value.
When is the queuing delay large and when is it insignificant? The answer to this
question depends on the rate at which traffic arrives at the queue, the transmission
rate of the link, and the nature of the arriving traffic, that is, whether the traffic arrives
periodically or arrives in bursts. To gain some insight here, let a denote the average
rate at which packets arrive at the queue (a is in units of packets/sec). Recall that R
is the transmission rate; that is, it is the rate (in bits/sec) at which bits are pushed out
of the queue. Also suppose, for simplicity, that all packets consist of L bits. Then the
average rate at which bits arrive at the queue is La bits/sec. Finally, assume that the
queue is very big, so that it can hold essentially an infinite number of bits. The ratio
La/R, called the traffic intensity, often plays an important role in estimating the
extent of the queuing delay. If La/R > 1, then the average rate at which bits arrive at
the queue exceeds the rate at which the bits can be transmitted from the queue. In this
unfortunate situation, the queue will tend to increase without bound and the queuing
delay will approach infinity! Therefore, one of the golden rules in traffic engineering
is: Design your system so that the traffic intensity is no greater than 1.
Now consider the case La/R ≤ 1. Here, the nature of the arriving traffic impacts
the queuing delay. For example, if packets arrive periodically—that is, one packet
arrives every L/R seconds—then every packet will arrive at an empty queue and
there will be no queuing delay. On the other hand, if packets arrive in bursts but
periodically, there can be a significant average queuing delay. For example, suppose N packets arrive simultaneously every (L/R)N seconds. Then the first packet
transmitted has no queuing delay; the second packet transmitted has a queuing delay

39

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

of L/R seconds; and more generally, the nth packet transmitted has a queuing delay
of (n - 1)L/R seconds. We leave it as an exercise for you to calculate the average
queuing delay in this example.
The two examples of periodic arrivals described above are a bit academic. Typically,
the arrival process to a queue is random; that is, the arrivals do not follow any pattern
and the packets are spaced apart by random amounts of time. In this more realistic case,
the quantity La/R is not usually sufficient to fully characterize the queuing delay statistics. Nonetheless, it is useful in gaining an intuitive understanding of the extent of the
queuing delay. In particular, if the traffic intensity is close to zero, then packet arrivals
are few and far between and it is unlikely that an arriving packet will find another packet
in the queue. Hence, the average queuing delay will be close to zero. On the other hand,
when the traffic intensity is close to 1, there will be intervals of time when the arrival
rate exceeds the transmission capacity (due to variations in packet arrival rate), and
a queue will form during these periods of time; when the arrival rate is less than the
transmission capacity, the length of the queue will shrink. Nonetheless, as the traffic
intensity approaches 1, the average queue length gets larger and larger. The qualitative
dependence of average queuing delay on the traffic intensity is shown in Figure 1.18.
One important aspect of Figure 1.18 is the fact that as the traffic intensity
approaches 1, the average queuing delay increases rapidly. A small percentage
increase in the intensity will result in a much larger percentage-wise increase in
delay. Perhaps you have experienced this phenomenon on the highway. If you regularly drive on a road that is typically congested, the fact that the road is typically
congested means that its traffic intensity is close to 1. If some event causes an even
slightly larger-than-usual amount of traffic, the delays you experience can be huge.
To really get a good feel for what queuing delays are about, you are encouraged
once again to visit the textbook Web site, which provides an interactive animation
for a queue. If you set the packet arrival rate high enough so that the traffic intensity
exceeds 1, you will see the queue slowly build up over time.

Average queuing delay

40

La/R

1

Figure 1.18 ♦ Dependence of average queuing delay on traffic intensity

1.4

•

DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS

41

Packet Loss
In our discussions above, we have assumed that the queue is capable of holding an
infinite number of packets. In reality a queue preceding a link has finite capacity,
although the queuing capacity greatly depends on the router design and cost. Because
the queue capacity is finite, packet delays do not really approach infinity as the traffic intensity approaches 1. Instead, a packet can arrive to find a full queue. With no
place to store such a packet, a router will drop that packet; that is, the packet will be
lost. This overflow at a queue can again be seen in the interactive animation when
the traffic intensity is greater than 1.
From an end-system viewpoint, a packet loss will look like a packet having
been transmitted into the network core but never emerging from the network at the
destination. The fraction of lost packets increases as the traffic intensity increases.
Therefore, performance at a node is often measured not only in terms of delay, but
also in terms of the probability of packet loss. As we’ll discuss in the subsequent
chapters, a lost packet may be retransmitted on an end-to-end basis in order to ensure
that all data are eventually transferred from source to destination.

1.4.3 End-to-End Delay
Our discussion up to this point has focused on the nodal delay, that is, the delay at a
single router. Let’s now consider the total delay from source to destination. To get a
handle on this concept, suppose there are N - 1 routers between the source host and
the destination host. Let’s also suppose for the moment that the network is uncongested (so that queuing delays are negligible), the processing delay at each router
and at the source host is dproc, the transmission rate out of each router and out of the
source host is R bits/sec, and the propagation on each link is dprop. The nodal delays
accumulate and give an end-to-end delay,
dend - end = N (dproc + dtrans + dprop)

(1.2)

where, once again, dtrans = L/R, where L is the packet size. Note that Equation 1.2 is a
generalization of Equation 1.1, which did not take into account processing and propagation delays. We leave it to you to generalize Equation 1.2 to the case of heterogeneous
delays at the nodes and to the presence of an average queuing delay at each node.

Traceroute
To get a hands-on feel for end-to-end delay in a computer network, we can make use
of the Traceroute program. Traceroute is a simple program that can run in any Internet host. When the user specifies a destination hostname, the program in the source
host sends multiple, special packets toward that destination. As these packets work
their way toward the destination, they pass through a series of routers. When a router
receives one of these special packets, it sends back to the source a short message that
contains the name and address of the router.

VideoNote
Using Traceroute to
discover network
paths and measure
network delay

42

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

More specifically, suppose there are N - 1 routers between the source and the
destination. Then the source will send N special packets into the network, with each
packet addressed to the ultimate destination. These N special packets are marked 1
through N, with the first packet marked 1 and the last packet marked N. When the
nth router receives the nth packet marked n, the router does not forward the packet
toward its destination, but instead sends a message back to the source. When the
destination host receives the Nth packet, it too returns a message back to the source.
The source records the time that elapses between when it sends a packet and when it
receives the corresponding return message; it also records the name and address of
the router (or the destination host) that returns the message. In this manner, the source
can reconstruct the route taken by packets flowing from source to destination, and the
source can determine the round-trip delays to all the intervening routers. Traceroute
actually repeats the experiment just described three times, so the source actually
sends 3 • N packets to the destination. RFC 1393 describes Traceroute in detail.
Here is an example of the output of the Traceroute program, where the route was
being traced from the source host gaia.cs.umass.edu (at the University of Massachusetts)
to a host in the computer science department at the University of Sorbonne in Paris
(formerly the university was known as UPMC). The output has six columns: the first
column is the n value described above, that is, the number of the router along the route;
the second column is the name of the router; the third column is the address of the router
(of the form xxx.xxx.xxx.xxx); the last three columns are the round-trip delays for three
experiments. If the source receives fewer than three messages from any given router
(due to packet loss in the network), Traceroute places an asterisk just after the router
number and reports fewer than three round-trip times for that router.
1
2

gw-vlan-2451.cs.umass.edu (128.119.245.1) 1.899 ms 3.266 ms 3.280 ms
j-cs-gw-int-10-240.cs.umass.edu (10.119.240.254) 1.296 ms 1.276 ms
1.245 ms
3 n5-rt-1-1-xe-2-1-0.gw.umass.edu (128.119.3.33) 2.237 ms 2.217 ms
2.187 ms
4 core1-rt-et-5-2-0.gw.umass.edu (128.119.0.9) 0.351 ms 0.392 ms 0.380 ms
5 border1-rt-et-5-0-0.gw.umass.edu (192.80.83.102) 0.345 ms 0.345 ms
0.344 ms
6 nox300gw1-umass-re.nox.org (192.5.89.101) 3.260 ms 0.416 ms 3.127 ms
7 nox300gw1-umass-re.nox.org (192.5.89.101) 3.165 ms 7.326 ms 7.311 ms
8 198.71.45.237 (198.71.45.237) 77.826 ms 77.246 ms 77.744 ms
9 renater-lb1-gw.mx1.par.fr.geant.net (62.40.124.70) 79.357 ms 77.729
79.152 ms
10 193.51.180.109 (193.51.180.109) 78.379 ms 79.936 80.042 ms
11 * 193.51.180.109 (193.51.180.109) 80.640 ms *
12 * 195.221.127.182 (195.221.127.182) 78.408 ms *
13 195.221.127.182 (195.221.127.182) 80.686 ms 80.796 ms 78.434 ms
14 r-upmc1.reseau.jussieu.fr (134.157.254.10) 78.399 ms * 81.353 ms

1.4

•

DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS

In the trace above, there are 14 routers between the source and the destination. Most
of these routers have a name, and all of them have addresses. For example, the
name of Router 4 is core1-rt-et-5-2-0.gw.umass.edu and its address is
128.119.0.9. Looking at the data provided for this same router, we see that in
the first of the three trials the round-trip delay between the source and the router
was 0.351 msec. The round-trip delays for the subsequent two trials were 0.392
and 0.380 msec. These round-trip delays include all of the delays just discussed,
including transmission delays, propagation delays, router processing delays, and
queuing delay.
Because the queuing delay is varying with time, the round-trip delay of
packet n sent to a router n can sometimes be longer than the round-trip delay of
packet n+1 sent to router n+1. Indeed, we observe this phenomenon in the above
example: the delay to Router 12 is smaller than the delay to Router 11! Also note
the big increase in the round-trip delay when going from router 7 to router 8. This
is due to a transatlantic fiber-optic link between routers 7 and 8, giving rise to a
relatively large propagation delay. There are a number of free software programs
that provide a graphical interface to Traceroute; one of our favorites is PingPlotter
[PingPlotter 2020].

End System, Application, and Other Delays
In addition to processing, transmission, and propagation delays, there can be additional significant delays in the end systems. For example, an end system wanting
to transmit a packet into a shared medium (e.g., as in a WiFi or cable modem scenario) may purposefully delay its transmission as part of its protocol for sharing the
medium with other end systems; we’ll consider such protocols in detail in Chapter 6.
Another important delay is media packetization delay, which is present in Voiceover-IP (VoIP) applications. In VoIP, the sending side must first fill a packet with
encoded digitized speech before passing the packet to the Internet. This time to fill a
packet—called the packetization delay—can be significant and can impact the userperceived quality of a VoIP call. This issue will be further explored in a homework
problem at the end of this chapter.

1.4.4 Throughput in Computer Networks
In addition to delay and packet loss, another critical performance measure in computer networks is end-to-end throughput. To define throughput, consider transferring
a large file from Host A to Host B across a computer network. This transfer might
be, for example, a large video clip from one computer to another. The instantaneous
throughput at any instant of time is the rate (in bits/sec) at which Host B is receiving
the file. (Many applications display the instantaneous throughput during downloads
in the user interface—perhaps you have observed this before! You might like to try

43

44

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

measuring the end-to-end delay and download throughput between your and servers
around the Internet using the speedtest application [Speedtest 2020].) If the file consists of F bits and the transfer takes T seconds for Host B to receive all F bits, then
the average throughput of the file transfer is F/T bits/sec. For some applications,
such as Internet telephony, it is desirable to have a low delay and an instantaneous
throughput consistently above some threshold (for example, over 24 kbps for some
Internet telephony applications and over 256 kbps for some real-time video applications). For other applications, including those involving file transfers, delay is not
critical, but it is desirable to have the highest possible throughput.
To gain further insight into the important concept of throughput, let’s consider
a few examples. Figure 1.19(a) shows two end systems, a server and a client, connected by two communication links and a router. Consider the throughput for a file
transfer from the server to the client. Let Rs denote the rate of the link between the
server and the router; and Rc denote the rate of the link between the router and
the client. Suppose that the only bits being sent in the entire network are those
from the server to the client. We now ask, in this ideal scenario, what is the serverto-client throughput? To answer this question, we may think of bits as fluid and communication links as pipes. Clearly, the server cannot pump bits through its link at a
rate faster than Rs bps; and the router cannot forward bits at a rate faster than Rc bps.
If Rs 6 Rc, then the bits pumped by the server will “flow” right through the router
and arrive at the client at a rate of Rs bps, giving a throughput of Rs bps. If, on the
other hand, Rc 6 Rs, then the router will not be able to forward bits as quickly as it
receives them. In this case, bits will only leave the router at rate Rc, giving an endto-end throughput of Rc. (Note also that if bits continue to arrive at the router at rate
Rs, and continue to leave the router at Rc, the backlog of bits at the router waiting
for transmission to the client will grow and grow—a most undesirable situation!)

Rc

Rs
Server
a.

Client

R1
Server

R2

RN
Client

b.

Figure 1.19 ♦ Throughput for a file transfer from server to client

1.4

•

DELAY, LOSS, AND THROUGHPUT IN PACKET-SWITCHED NETWORKS

Thus,!for this simple two-link network, the throughput is min{Rc, Rs}, that is, it is!the
transmission rate of the bottleneck link. Having determined the throughput, we can
now approximate the time it takes to transfer a large file of F bits from server to client as F/min{Rs, Rc}. For a specific example, suppose that you are downloading an
MP3 file of F = 32 million bits, the server has a transmission rate of Rs = 2 Mbps,
and you have an access link of Rc = 1 Mbps. The time needed to transfer the file is
then 32 seconds. Of course, these expressions for throughput and transfer time are
only approximations, as they do not account for store-and-forward and processing
delays as well as protocol issues.
Figure 1.19(b) now shows a network with N links between the server and the
client, with the transmission rates of the N links being R1, R2, c, RN . Applying
the same analysis as for the two-link network, we find that the throughput for a file
transfer from server to client is min{R1, R2, c, RN}, which is once again the transmission rate of the bottleneck link along the path between server and client.
Now consider another example motivated by today’s Internet. Figure 1.20(a)
shows two end systems, a server and a client, connected to a computer network.
Consider the throughput for a file transfer from the server to the client. The server is
connected to the network with an access link of rate Rs and the client is connected to
the network with an access link of rate Rc. Now suppose that all the links in the core
of the communication network have very high transmission rates, much higher than
Rs and Rc. Indeed, today, the core of the Internet is over-provisioned with high speed
links that experience little congestion. Also suppose that the only bits being sent in
the entire network are those from the server to the client. Because the core of the
computer network is like a wide pipe in this example, the rate at which bits can flow
from source to destination is again the minimum of Rs and Rc, that is, throughput =
min{Rs, Rc}. Therefore, the constraining factor for throughput in today’s Internet is
typically the access network.
For a final example, consider Figure 1.20(b) in which there are 10 servers and
10 clients connected to the core of the computer network. In this example, there are
10 simultaneous downloads taking place, involving 10 client-server pairs. Suppose
that these 10 downloads are the only traffic in the network at the current time. As
shown in the figure, there is a link in the core that is traversed by all 10 downloads.
Denote R for the transmission rate of this link R. Let’s suppose that all server access
links have the same rate Rs, all client access links have the same rate Rc, and the
transmission rates of all the links in the core—except the one common link of rate
R—are much larger than Rs, Rc, and R. Now we ask, what are the throughputs of
the downloads? Clearly, if the rate of the common link, R, is large—say a hundred
times larger than both Rs and Rc—then the throughput for each download will once
again be min{Rs, Rc}. But what if the rate of the common link is of the same order
as Rs and Rc? What will the throughput be in this case? Let’s take a look at a specific example. Suppose Rs = 2 Mbps, Rc = 1 Mbps, R = 5 Mbps, and the common link divides its transmission rate equally among the 10 downloads. Then the

45

46

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

Server

10 Servers

Rs

Bottleneck
link of
capacity R

Rc

Client
a.

10 Clients
b.

Figure 1.20 ♦ End-to-end throughput: (a) Client downloads a file from
server; (b) 10 clients downloading with 10 servers

bottleneck for each download is no longer in the access network, but is now instead
the shared link in the core, which only provides each download with 500 kbps of
throughput. Thus, the end-to-end throughput for each download is now reduced to
500 kbps.
The examples in Figure 1.19 and Figure 1.20(a) show that throughput depends
on the transmission rates of the links over which the data flows. We saw that when
there is no other intervening traffic, the throughput can simply be approximated as
the minimum transmission rate along the path between source and destination. The
example in Figure 1.20(b) shows that more generally the throughput depends not
only on the transmission rates of the links along the path, but also on the intervening traffic. In particular, a link with a high transmission rate may nonetheless be the
bottleneck link for a file transfer if many other data flows are also passing through
that link. We will examine throughput in computer networks more closely in the
homework problems and in the subsequent chapters.

1.5

•

PROTOCOL LAYERS AND THEIR SERVICE MODELS

1.5 Protocol Layers and Their Service Models
From our discussion thus far, it is apparent that the Internet is an extremely complicated system. We have seen that there are many pieces to the Internet: numerous
applications and protocols, various types of end systems, packet switches, and various types of link-level media. Given this enormous complexity, is there any hope of
organizing a network architecture, or at least our discussion of network architecture?
Fortunately, the answer to both questions is yes.

1.5.1 Layered Architecture
Before attempting to organize our thoughts on Internet architecture, let’s look
for a human analogy. Actually, we deal with complex systems all the time in our
everyday life. Imagine if someone asked you to describe, for example, the airline system. How would you find the structure to describe this complex system
that has ticketing agents, baggage checkers, gate personnel, pilots, airplanes,
air traffic control, and a worldwide system for routing airplanes? One way to
describe this system might be to describe the series of actions you take (or others take for you) when you fly on an airline. You purchase your ticket, check
your bags, go to the gate, and eventually get loaded onto the plane. The plane
takes off and is routed to its destination. After your plane lands, you deplane at
the gate and claim your bags. If the trip was bad, you complain about the flight
to the ticket agent (getting nothing for your effort). This scenario is shown in
Figure 1.21.

Ticket (purchase)

Ticket (complain)

Baggage (check)

Baggage (claim)

Gates (load)

Gates (unload)

Runway takeoff

Runway landing

Airplane routing

Airplane routing

Airplane routing

Figure 1.21 ♦ Taking an airplane trip: actions

47

48

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

Ticket (purchase)

Ticket (complain) Ticket

Baggage (check)

Baggage (claim)

Baggage

Gates (load)

Gates (unload)

Gate

Runway takeoff

Runway landing

Takeoff/Landing

Airplane routing
Departure airport

Airplane routing

Airplane routing

Intermediate air-traffic
control centers

Airplane routing Airplane routing
Arrival airport

Figure 1.22 ♦ Horizontal layering of airline functionality
Already, we can see some analogies here with computer networking: You are
being shipped from source to destination by the airline; a packet is shipped from
source host to destination host in the Internet. But this is not quite the analogy we
are after. We are looking for some structure in Figure 1.21. Looking at Figure 1.21,
we note that there is a ticketing function at each end; there is also a baggage function for already-ticketed passengers, and a gate function for already-ticketed and
already-baggage-checked passengers. For passengers who have made it through the
gate (that is, passengers who are already ticketed, baggage-checked, and through the
gate), there is a takeoff and landing function, and while in flight, there is an airplanerouting function. This suggests that we can look at the functionality in Figure 1.21 in
a horizontal manner, as shown in Figure 1.22.
Figure 1.22 has divided the airline functionality into layers, providing a framework in which we can discuss airline travel. Note that each layer, combined with the
layers below it, implements some functionality, some service. At the ticketing layer
and below, airline-counter-to-airline-counter transfer of a person is accomplished. At
the baggage layer and below, baggage-check-to-baggage-claim transfer of a person
and bags is accomplished. Note that the baggage layer provides this service only to an
already-ticketed person. At the gate layer, departure-gate-to-arrival-gate transfer of
a person and bags is accomplished. At the takeoff/landing layer, runway-to-runway
transfer of people and their bags is accomplished. Each layer provides its service
by (1) performing certain actions within that layer (for example, at the gate layer,
loading and unloading people from an airplane) and by (2) using the services of the
layer directly below it (for example, in the gate layer, using the runway-to-runway
passenger transfer service of the takeoff/landing layer).
A layered architecture allows us to discuss a well-defined, specific part of a
large and complex system. This simplification itself is of considerable value by
providing modularity, making it much easier to change the implementation of the
service provided by the layer. As long as the layer provides the same service to the
layer above it, and uses the same services from the layer below it, the remainder of
the system remains unchanged when a layer’s implementation is changed. (Note

1.5

•

PROTOCOL LAYERS AND THEIR SERVICE MODELS

that changing the implementation of a service is very different from changing the
service itself!) For example, if the gate functions were changed (for instance, to have
people board and disembark by height), the remainder of the airline system would
remain unchanged since the gate layer still provides the same function (loading and
unloading people); it simply implements that function in a different manner after the
change. For large and complex systems that are constantly being updated, the ability
to change the implementation of a service without affecting other components of the
system is another important advantage of layering.

Protocol Layering
But enough about airlines. Let’s now turn our attention to network protocols. To
provide structure to the design of network protocols, network designers organize
protocols—and the network hardware and software that implement the protocols—
in layers. Each protocol belongs to one of the layers, just as each function in the
airline architecture in Figure 1.22 belonged to a layer. We are again interested in
the services that a layer offers to the layer above—the so-called service model of
a layer. Just as in the case of our airline example, each layer provides its service by
(1) performing certain actions within that layer and by (2) using the services of the
layer directly below it. For example, the services provided by layer n may include
reliable delivery of messages from one edge of the network to the other. This might
be implemented by using an unreliable edge-to-edge message delivery service of
layer n - 1, and adding layer n functionality to detect and retransmit lost messages.
A protocol layer can be implemented in software, in hardware, or in a combination of the two. Application-layer protocols—such as HTTP and SMTP—are almost
always implemented in software in the end systems; so are transport-layer protocols.
Because the physical layer and data link layers are responsible for handling communication over a specific link, they are typically implemented in a network interface
card (for example, Ethernet or WiFi interface cards) associated with a given link. The
network layer is often a mixed implementation of hardware and software. Also note
that just as the functions in the layered airline architecture were distributed among
the various airports and flight control centers that make up the system, so too is a
layer n protocol distributed among the end systems, packet switches, and other components that make up the network. That is, there’s often a piece of a layer n protocol
in each of these network components.
Protocol layering has conceptual and structural advantages [RFC 3439]. As
we have seen, layering provides a structured way to discuss system components.
Modularity makes it easier to update system components. We mention, however,
that some researchers and networking engineers are vehemently opposed to layering
[Wakeman 1992]. One potential drawback of layering is that one layer may duplicate
lower-layer functionality. For example, many protocol stacks provide error recovery
on both a per-link basis and an end-to-end basis. A second potential drawback is that
functionality at one layer may need information (for example, a timestamp value)
that is present only in another layer; this violates the goal of separation of layers.

49

50

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

Application
Transport
Network
Link
Physical
Five-layer
Internet
protocol stack

Figure 1.23 ♦ The Internet protocol stack
When taken together, the protocols of the various layers are called the protocol
stack. The Internet protocol stack consists of five layers: the physical, link, network,
transport, and application layers, as shown in Figure 1.23. If you examine the Table
of Contents, you will see that we have roughly organized this book using the layers of the Internet protocol stack. We take a top-down approach, first covering the
application layer and then proceeding downward.

Application Layer
The application layer is where network applications and their application-layer protocols reside. The Internet’s application layer includes many protocols, such as the
HTTP protocol (which provides for Web document request and transfer), SMTP
(which provides for the transfer of e-mail messages), and FTP (which provides for
the transfer of files between two end systems). We’ll see that certain network functions, such as the translation of human-friendly names for Internet end systems like
www.ietf.org to a 32-bit network address, are also done with the help of a specific application-layer protocol, namely, the domain name system (DNS). We’ll see in Chapter!2 that it is very easy to create and deploy our own new application-layer protocols.
An application-layer protocol is distributed over multiple end systems, with the
application in one end system using the protocol to exchange packets of information
with the application in another end system. We’ll refer to this packet of information
at the application layer as a message.

Transport Layer
The Internet’s transport layer transports application-layer messages between application
endpoints. In the Internet, there are two transport protocols, TCP and UDP, either of
which can transport application-layer messages. TCP provides a connection-oriented
service to its applications. This service includes guaranteed delivery of application-layer

1.5

•

PROTOCOL LAYERS AND THEIR SERVICE MODELS

messages to the destination and flow control (that is, sender/receiver speed matching).
TCP also breaks long messages into shorter segments and provides a congestion-control
mechanism, so that a source throttles its transmission rate when the network is congested. The UDP protocol provides a connectionless service to its applications. This is a
no-frills service that provides no reliability, no flow control, and no congestion control.
In this book, we’ll refer to a transport-layer packet as a segment.

Network Layer
The Internet’s network layer is responsible for moving network-layer packets known
as datagrams from one host to another. The Internet transport-layer protocol (TCP
or UDP) in a source host passes a transport-layer segment and a destination address
to the network layer, just as you would give the postal service a letter with a destination address. The network layer then provides the service of delivering the segment
to the transport layer in the destination host.
The Internet’s network layer includes the celebrated IP protocol, which defines
the fields in the datagram as well as how the end systems and routers act on these
fields. There is only one IP protocol, and all Internet components that have a network
layer must run the IP protocol. The Internet’s network layer also contains routing
protocols that determine the routes that datagrams take between sources and destinations. The Internet has many routing protocols. As we saw in Section 1.3, the Internet
is a network of networks, and within a network, the network administrator can run
any routing protocol desired. Although the network layer contains both the IP protocol and numerous routing protocols, it is often simply referred to as the IP layer,
reflecting the fact that IP is the glue that binds the Internet together.

Link Layer
The Internet’s network layer routes a datagram through a series of routers between
the source and destination. To move a packet from one node (host or router) to the
next node in the route, the network layer relies on the services of the link layer. In
particular, at each node, the network layer passes the datagram down to the link
layer, which delivers the datagram to the next node along the route. At this next node,
the link layer passes the datagram up to the network layer.
The services provided by the link layer depend on the specific link-layer protocol
that is employed over the link. For example, some link-layer protocols provide reliable delivery, from transmitting node, over one link, to receiving node. Note that this
reliable delivery service is different from the reliable delivery service of TCP, which
provides reliable delivery from one end system to another. Examples of link-layer protocols include Ethernet, WiFi, and the cable access network’s DOCSIS protocol. As
datagrams typically need to traverse several links to travel from source to destination,
a datagram may be handled by different link-layer protocols at different links along its
route. For example, a datagram may be handled by Ethernet on one link and by PPP on

51

52

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

the next link. The network layer will receive a different service from each of the different link-layer protocols. In this book, we’ll refer to the link-layer packets as frames.

Physical Layer
While the job of the link layer is to move entire frames from one network element to
an adjacent network element, the job of the physical layer is to move the individual
bits within the frame from one node to the next. The protocols in this layer are again
link dependent and further depend on the actual transmission medium of the link (for
example, twisted-pair copper wire, single-mode fiber optics). For example, Ethernet has many physical-layer protocols: one for twisted-pair copper wire, another for
coaxial cable, another for fiber, and so on. In each case, a bit is moved across the link
in a different way.

1.5.2 Encapsulation
Figure 1.24 shows the physical path that data takes down a sending end system’s
protocol stack, up and down the protocol stacks of an intervening link-layer switch
Source
Message

M

Segment Ht M
Datagram
Frame

Hn Ht M

H l Hn Ht M

Application
Transport
Network
Link
Physical
H l Hn Ht M

Link

H l Hn Ht M

Physical
Link-layer switch

Destination
M

Router

Application

Ht M

Transport

Hn Ht M

Hn Ht M

Network

H l Hn Ht M

H l Hn Ht M

Link

Network
Link

Hn Ht M
H l Hn Ht M

Physical

Physical

Figure 1.24 ♦ Hosts, routers, and link-layer switches; each contains a
different set of layers, reflecting their differences in functionality

1.5

•

PROTOCOL LAYERS AND THEIR SERVICE MODELS

and router, and then up the protocol stack at the receiving end system. As we discuss later in this book, routers and link-layer switches are both packet switches.
Similar to end systems, routers and link-layer switches organize their networking hardware and software into layers. But routers and link-layer switches do not
implement all of the layers in the protocol stack; they typically implement only
the bottom layers. As shown in Figure 1.24, link-layer switches implement layers 1 and 2; routers implement layers 1 through 3. This means, for example, that
Internet routers are capable of implementing the IP protocol (a layer 3 protocol),
while link-layer switches are not. We’ll see later that while link-layer switches do
not recognize IP addresses, they are capable of recognizing layer 2 addresses, such
as Ethernet addresses. Note that hosts implement all five layers; this is consistent
with the view that the Internet architecture puts much of its complexity at the edges
of the network.
Figure 1.24 also illustrates the important concept of encapsulation. At the
sending host, an application-layer message (M in Figure 1.24) is passed to the
transport layer. In the simplest case, the transport layer takes the message and
appends additional information (so-called transport-layer header information, Ht
in Figure 1.24) that will be used by the receiver-side transport layer. The application-layer message and the transport-layer header information together constitute the transport-layer segment. The transport-layer segment thus encapsulates
the application-layer message. The added information might include information
allowing the receiver-side transport layer to deliver the message up to the appropriate application, and error-detection bits that allow the receiver to determine
whether bits in the message have been changed in route. The transport layer then
passes the segment to the network layer, which adds network-layer header information (Hn in Figure 1.24) such as source and destination end system addresses,
creating a network-layer datagram. The datagram is then passed to the link
layer, which (of course!) will add its own link-layer header information and create a link-layer frame. Thus, we see that at each layer, a packet has two types of
fields: header fields and a payload field. The payload is typically a packet from
the layer above.
A useful analogy here is the sending of an interoffice memo from one corporate branch office to another via the public postal service. Suppose Alice, who is in
one branch office, wants to send a memo to Bob, who is in another branch office.
The memo is analogous to the application-layer message. Alice puts the memo
in an interoffice envelope with Bob’s name and department written on the front
of the envelope. The interoffice envelope is analogous to a transport-layer segment—it contains header information (Bob’s name and department number) and it
encapsulates the application-layer message (the memo). When the sending branchoffice mailroom receives the interoffice envelope, it puts the interoffice envelope inside yet another envelope, which is suitable for sending through the public
postal service. The sending mailroom also writes the postal address of the sending
and receiving branch offices on the postal envelope. Here, the postal envelope

53

54

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

is analogous to the datagram—it encapsulates the transport-layer segment (the
interoffice envelope), which encapsulates the original message (the memo). The
postal service delivers the postal envelope to the receiving branch-office mailroom. There, the process of de-encapsulation is begun. The mailroom extracts the
interoffice memo and forwards it to Bob. Finally, Bob opens the envelope and
removes the memo.
The process of encapsulation can be more complex than that described above.
For example, a large message may be divided into multiple transport-layer segments
(which might themselves each be divided into multiple network-layer datagrams).
At the receiving end, such a segment must then be reconstructed from its constituent
datagrams.

1.6 Networks Under Attack
The Internet has become mission critical for many institutions today, including large
and small companies, universities, and government agencies. Many individuals also
rely on the Internet for many of their professional, social, and personal activities.
Billions of “things,” including wearables and home devices, are currently being connected to the Internet. But behind all this utility and excitement, there is a dark side,
a side where “bad guys” attempt to wreak havoc in our daily lives by damaging our
Internet-connected computers, violating our privacy, and rendering inoperable the
Internet services on which we depend.
The field of network security is about how the bad guys can attack computer
networks and about how we, soon-to-be experts in computer networking, can
defend networks against those attacks, or better yet, design new architectures
that are immune to such attacks in the first place. Given the frequency and variety of existing attacks as well as the threat of new and more destructive future
attacks, network security has become a central topic in the field of computer
networking. One of the features of this textbook is that it brings network security
issues to the forefront.
Since we don’t yet have expertise in computer networking and Internet protocols, we’ll begin here by surveying some of today’s more prevalent securityrelated problems. This will whet our appetite for more substantial discussions in the
upcoming chapters. So we begin here by simply asking, what can go wrong? How
are computer networks vulnerable? What are some of the more prevalent types of
attacks today?

The Bad Guys Can Put Malware into Your Host Via the Internet
We attach devices to the Internet because we want to receive/send data from/to the
Internet. This includes all kinds of good stuff, including Instagram posts, Internet

1.6

•

NETWORKS UNDER ATTACK

search results, streaming music, video conference calls, streaming movies, and
so on. But, unfortunately, along with all that good stuff comes malicious stuff—
collectively known as malware—that can also enter and infect our devices. Once
malware infects our device it can do all kinds of devious things, including deleting our files and installing spyware that collects our private information, such
as!social security numbers, passwords, and keystrokes, and then sends this (over
the Internet, of course!) back to the bad guys. Our compromised host may also
be! enrolled in a network of thousands of similarly compromised devices, collectively known as a botnet, which the bad guys control and leverage for spam
e-mail distribution or distributed denial-of-service attacks (soon to be discussed)
against targeted hosts.
Much of the malware out there today is self-replicating: once it infects one host,
from that host it seeks entry into other hosts over the Internet, and from the newly
infected hosts, it seeks entry into yet more hosts. In this manner, self-replicating malware can spread exponentially fast.

The Bad Guys Can Attack Servers and Network Infrastructure
Another broad class of security threats are known as denial-of-service (DoS)
attacks. As the name suggests, a DoS attack renders a network, host, or other piece
of infrastructure unusable by legitimate users. Web servers, e-mail servers, DNS
servers (discussed in Chapter 2), and institutional networks can all be subject to DoS
attacks. The site Digital Attack Map allows use to visualize the top daily DoS attacks
worldwide [DAM 2020]. Most Internet DoS attacks fall into one of three categories:
• Vulnerability attack. This involves sending a few well-crafted messages to a
vulnerable application or operating system running on a targeted host. If the right
sequence of packets is sent to a vulnerable application or operating system, the
service can stop or, worse, the host can crash.
• Bandwidth flooding. The attacker sends a deluge of packets to the targeted
host—so many packets that the target’s access link becomes clogged, preventing
legitimate packets from reaching the server.
• Connection flooding. The attacker establishes a large number of half-open or
fully open TCP connections (TCP connections are discussed in Chapter 3) at the
target host. The host can become so bogged down with these bogus connections
that it stops accepting legitimate connections.
Let’s now explore the bandwidth-flooding attack in more detail. Recalling our
delay and loss analysis discussion in Section 1.4.2, it’s evident that if the server
has an access rate of R bps, then the attacker will need to send traffic at a rate of
approximately R bps to cause damage. If R is very large, a single attack source
may not be able to generate enough traffic to harm the server. Furthermore, if all

55

56

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

zombie
zombie

“start
attack”

Victim

zombie

Attacker
zombie
zombie

Figure 1.25 ♦ A distributed denial-of-service attack

the traffic emanates from a single source, an upstream router may be able to detect
the attack and block all traffic from that source before the traffic gets near the
server. In a distributed DoS (DDoS) attack, illustrated in Figure 1.25, the attacker
controls multiple sources and has each source blast traffic at the target. With this
approach, the aggregate traffic rate across all the controlled sources needs to be
approximately R to cripple the service. DDoS attacks leveraging botnets with thousands of comprised hosts are a common occurrence today [DAM 2020]. DDos
attacks are much harder to detect and defend against than a DoS attack from a
single host.
We encourage you to consider the following question as you work your way
through this book: What can computer network designers do to defend against
DoS attacks? We will see that different defenses are needed for the three types of
DoS attacks.

The Bad Guys Can Sniff Packets
Many users today access the Internet via wireless devices, such as WiFi-connected
laptops or handheld devices with cellular Internet connections (covered in Chapter 7).
While ubiquitous Internet access is extremely convenient and enables marvelous
new applications for mobile users, it also creates a major security vulnerability—by
placing a passive receiver in the vicinity of the wireless transmitter, that receiver

1.6

•

NETWORKS UNDER ATTACK

can obtain a copy of every packet that is transmitted! These packets can contain all
kinds of sensitive information, including passwords, social security numbers, trade
secrets, and private personal messages. A passive receiver that records a copy of
every packet that flies by is called a packet sniffer.
Sniffers can be deployed in wired environments as well. In wired broadcast
environments, as in many Ethernet LANs, a packet sniffer can obtain copies of
broadcast packets sent over the LAN. As described in Section 1.2, cable access
technologies also broadcast packets and are thus vulnerable to sniffing. Furthermore, a bad guy who gains access to an institution’s access router or access link
to the Internet may be able to plant a sniffer that makes a copy of every packet
going to/from the organization. Sniffed packets can then be analyzed offline for
sensitive information.
Packet-sniffing software is freely available at various Web sites and as commercial products. Professors teaching a networking course have been known to assign
lab exercises that involve writing a packet-sniffing and application-layer data reconstruction program. Indeed, the Wireshark [Wireshark 2020] labs associated with this
text (see the introductory Wireshark lab at the end of this chapter) use exactly such
a packet sniffer!
Because packet sniffers are passive—that is, they do not inject packets into the
channel—they are difficult to detect. So, when we send packets into a wireless channel, we must accept the possibility that some bad guy may be recording copies of our
packets. As you may have guessed, some of the best defenses against packet sniffing
involve cryptography. We will examine cryptography as it applies to network security in Chapter 8.

The Bad Guys Can Masquerade as Someone You Trust
It is surprisingly easy (you will have the knowledge to do so shortly as you proceed
through this text!) to create a packet with an arbitrary source address, packet content,
and destination address and then transmit this hand-crafted packet into the Internet,
which will dutifully forward the packet to its destination. Imagine the unsuspecting
receiver (say an Internet router) who receives such a packet, takes the (false) source
address as being truthful, and then performs some command embedded in the packet’s contents (say modifies its forwarding table). The ability to inject packets into the
Internet with a false source address is known as IP spoofing, and is but one of many
ways in which one user can masquerade as another user.
To solve this problem, we will need end-point authentication, that is, a mechanism that will allow us to determine with certainty if a message originates from
where we think it does. Once again, we encourage you to think about how this
can be done for network applications and protocols as you progress through the
chapters of this book. We will explore mechanisms for end-point authentication
in Chapter 8.

57

58

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

In closing this section, it’s worth considering how the Internet got to be such
an insecure place in the first place. The answer, in essence, is that the Internet was
originally designed to be that way, based on the model of “a group of mutually trusting users attached to a transparent network” [Blumenthal 2001]—a model in which
(by definition) there is no need for security. Many aspects of the original Internet
architecture deeply reflect this notion of mutual trust. For example, the ability for
one user to send a packet to any other user is the default rather than a requested/
granted capability, and user identity is taken at declared face value, rather than being
authenticated by default.
But today’s Internet certainly does not involve “mutually trusting users.” Nonetheless, today’s users still need to communicate when they don’t necessarily trust
each other, may wish to communicate anonymously, may communicate indirectly
through third parties (e.g., Web caches, which we’ll study in Chapter 2, or mobilityassisting agents, which we’ll study in Chapter 7), and may distrust the hardware,
software, and even the air through which they communicate. We now have many
security-related challenges before us as we progress through this book: We should
seek defenses against sniffing, end-point masquerading, man-in-the-middle attacks,
DDoS attacks, malware, and more. We should keep in mind that communication
among mutually trusted users is the exception rather than the rule. Welcome to the
world of modern computer networking!

1.7 History of Computer Networking and
the Internet

Sections 1.1 through 1.6 presented an overview of the technology of computer networking and the Internet. You should know enough now to impress your family and
friends! However, if you really want to be a big hit at the next cocktail party, you
should sprinkle your discourse with tidbits about the fascinating history of the Internet [Segaller 1998].

1.7.1 The Development of Packet Switching: 1961–1972
The field of computer networking and today’s Internet trace their beginnings
back to the early 1960s, when the telephone network was the world’s dominant
communication network. Recall from Section 1.3 that the telephone network uses
circuit switching to transmit information from a sender to a receiver—an appropriate choice given that voice is transmitted at a constant rate between sender
and receiver. Given the increasing importance of computers in the early 1960s
and the advent of timeshared computers, it was perhaps natural to consider how
to hook computers together so that they could be shared among geographically

1.7

•

HISTORY OF COMPUTER NETWORKING AND THE INTERNET

distributed users. The traffic generated by such users was likely to be bursty—
intervals of activity, such as the sending of a command to a remote computer,
followed by periods of inactivity while waiting for a reply or while contemplating the received response.
Three research groups around the world, each unaware of the others’ work
[Leiner 1998], began inventing packet switching as an efficient and robust alternative to circuit switching. The first published work on packet-switching techniques
was that of Leonard Kleinrock [Kleinrock 1961; Kleinrock 1964], then a graduate
student at MIT. Using queuing theory, Kleinrock’s work elegantly demonstrated the
effectiveness of the packet-switching approach for bursty traffic sources. In 1964,
Paul Baran [Baran 1964] at the Rand Institute had begun investigating the use of
packet switching for secure voice over military networks, and at the National Physical Laboratory in England, Donald Davies and Roger Scantlebury were also developing their ideas on packet switching.
The work at MIT, Rand, and the NPL laid the foundations for today’s Internet. But the Internet also has a long history of a let’s-build-it-and-demonstrate-it
attitude that also dates back to the 1960s. J. C. R. Licklider [DEC 1990] and
Lawrence Roberts, both colleagues of Kleinrock’s at MIT, went on to lead the
computer science program at the Advanced Research Projects Agency (ARPA)
in the United States. Roberts published an overall plan for the ARPAnet [Roberts
1967], the first packet-switched computer network and a direct ancestor of today’s
public Internet. On Labor Day in 1969, the first packet switch was installed at
UCLA under Kleinrock’s supervision, and three additional packet switches were
installed shortly thereafter at the Stanford Research Institute (SRI), UC Santa
Barbara, and the University of Utah (Figure 1.26). The fledgling precursor to the
Internet was four nodes large by the end of 1969. Kleinrock recalls the very first
use of the network to perform a remote login from UCLA to SRI, crashing the
system [Kleinrock 2004].
By 1972, ARPAnet had grown to approximately 15 nodes and was given its
first public demonstration by Robert Kahn. The first host-to-host protocol between
ARPAnet end systems, known as the network-control protocol (NCP), was completed [RFC 001]. With an end-to-end protocol available, applications could now be
written. Ray Tomlinson wrote the first e-mail program in 1972.

1.7.2 Proprietary Networks and Internetworking:
1972–1980
The initial ARPAnet was a single, closed network. In order to communicate with an
ARPAnet host, one had to be actually attached to another ARPAnet IMP. In the early
to mid-1970s, additional stand-alone packet-switching networks besides ARPAnet
came into being: ALOHANet, a microwave network linking universities on the
Hawaiian islands [Abramson 1970], as well as DARPA’s packet-satellite [RFC 829]
and packet-radio networks [Kahn 1978]; Telenet, a BBN commercial packet-switching

59

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

Mark J. Terrill/AP Photo

60

Figure 1.26 ♦ An early packet switch

network based on ARPAnet technology; Cyclades, a French packet-switching network pioneered by Louis Pouzin [Think 2012]; Time-sharing networks such as
Tymnet and the GE Information Services network, among others, in the late 1960s
and early 1970s [Schwartz 1977]; IBM’s SNA (1969–1974), which paralleled the
ARPAnet work [Schwartz 1977].
The number of networks was growing. With perfect hindsight we can see that the
time was ripe for developing an encompassing architecture for connecting networks
together. Pioneering work on interconnecting networks (under the sponsorship of
the Defense Advanced Research Projects Agency (DARPA)), in essence creating

1.7

•

HISTORY OF COMPUTER NETWORKING AND THE INTERNET

a network of networks, was done by Vinton Cerf and Robert Kahn [Cerf 1974]; the
term internetting was coined to describe this work.
These architectural principles were embodied in TCP. The early versions of
TCP, however, were quite different from today’s TCP. The early versions of TCP
combined a reliable in-sequence delivery of data via end-system retransmission (still
part of today’s TCP) with forwarding functions (which today are performed by IP).
Early experimentation with TCP, combined with the recognition of the importance
of an unreliable, non-flow-controlled, end-to-end transport service for applications
such as packetized voice, led to the separation of IP out of TCP and the development
of the UDP protocol. The three key Internet protocols that we see today—TCP, UDP,
and IP—were conceptually in place by the end of the 1970s.
In addition to the DARPA Internet-related research, many other important networking activities were underway. In Hawaii, Norman Abramson was developing
ALOHAnet, a packet-based radio network that allowed multiple remote sites
on the Hawaiian Islands to communicate with each other. The ALOHA protocol
[Abramson 1970] was the first multiple-access protocol, allowing geographically
distributed users to share a single broadcast communication medium (a radio
frequency). Metcalfe and Boggs built on Abramson’s multiple-access protocol work
when they developed the Ethernet protocol [Metcalfe 1976] for wire-based shared
broadcast networks. Interestingly, Metcalfe and Boggs’ Ethernet protocol was motivated by the need to connect multiple PCs, printers, and shared disks [Perkins 1994].
Twenty-five years ago, well before the PC revolution and the explosion of networks,
Metcalfe and Boggs were laying the foundation for today’s PC LANs.

1.7.3 A Proliferation of Networks: 1980–1990
By the end of the 1970s, approximately two hundred hosts were connected to the
ARPAnet. By the end of the 1980s the number of hosts connected to the public
Internet, a confederation of networks looking much like today’s Internet, would
reach a hundred thousand. The 1980s would be a time of tremendous growth.
Much of that growth resulted from several distinct efforts to create computer
networks linking universities together. BITNET provided e-mail and file transfers
among several universities in the Northeast. CSNET (computer science network)
was formed to link university researchers who did not have access to ARPAnet. In
1986, NSFNET was created to provide access to NSF-sponsored supercomputing
centers. Starting with an initial backbone speed of 56 kbps, NSFNET’s backbone
would be running at 1.5 Mbps by the end of the decade and would serve as a primary
backbone linking regional networks.
In the ARPAnet community, many of the final pieces of today’s Internet architecture were falling into place. January 1, 1983 saw the official deployment of
TCP/IP as the new standard host protocol for ARPAnet (replacing the NCP protocol). The transition [RFC 801] from NCP to TCP/IP was a flag day event—all
hosts were required to transfer over to TCP/IP as of that day. In the late 1980s,

61

62

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

important extensions were made to TCP to implement host-based congestion control [Jacobson 1988]. The DNS, used to map between a human-readable Internet
name (for example, gaia.cs.umass.edu) and its 32-bit IP address, was also developed
[RFC 1034].
Paralleling this development of the ARPAnet (which was for the most part a
US effort), in the early 1980s the French launched the Minitel project, an ambitious
plan to bring data networking into everyone’s home. Sponsored by the French government, the Minitel system consisted of a public packet-switched network (based
on the X.25 protocol suite), Minitel servers, and inexpensive terminals with built-in
low-speed modems. The Minitel became a huge success in 1984 when the French
government gave away a free Minitel terminal to each French household that wanted
one. Minitel sites included free sites—such as a telephone directory site—as well as
private sites, which collected a usage-based fee from each user. At its peak in the
mid 1990s, it offered more than 20,000 services, ranging from home banking to specialized research databases. The Minitel was in a large proportion of French homes
10!years before most Americans had ever heard of the Internet.

1.7.4 The Internet Explosion: The 1990s
The 1990s were ushered in with a number of events that symbolized the continued
evolution and the soon-to-arrive commercialization of the Internet. ARPAnet, the
progenitor of the Internet, ceased to exist. In 1991, NSFNET lifted its restrictions on
the use of NSFNET for commercial purposes. NSFNET itself would be decommissioned in 1995, with Internet backbone traffic being carried by commercial Internet
Service Providers.
The main event of the 1990s was to be the emergence of the World Wide Web
application, which brought the Internet into the homes and businesses of millions
of people worldwide. The Web served as a platform for enabling and deploying
hundreds of new applications that we take for granted today, including search (e.g.,
Google and Bing) Internet commerce (e.g., Amazon and eBay) and social networks
(e.g., Facebook).
The Web was invented at CERN by Tim Berners-Lee between 1989 and 1991
[Berners-Lee 1989], based on ideas originating in earlier work on hypertext from the
1940s by Vannevar Bush [Bush 1945] and since the 1960s by Ted Nelson [Xanadu
2012]. Berners-Lee and his associates developed initial versions of HTML, HTTP,
a Web server, and a browser—the four key components of the Web. Around the end
of 1993 there were about two hundred Web servers in operation, this collection of
servers being just a harbinger of what was about to come. At about this time several researchers were developing Web browsers with GUI interfaces, including Marc
Andreessen, who along with Jim Clark, formed Mosaic Communications, which
later became Netscape Communications Corporation [Cusumano 1998; Quittner
1998]. By 1995, university students were using Netscape browsers to surf the Web
on a daily basis. At about this time companies—big and small—began to operate

1.7

•

HISTORY OF COMPUTER NETWORKING AND THE INTERNET

Web servers and transact commerce over the Web. In 1996, Microsoft started to
make browsers, which started the browser war between Netscape and Microsoft,
which Microsoft won a few years later [Cusumano 1998].
The second half of the 1990s was a period of tremendous growth and innovation
for the Internet, with major corporations and thousands of startups creating Internet
products and services. By the end of the millennium the Internet was supporting
hundreds of popular applications, including four killer applications:
•
•
•
•

E-mail, including attachments and Web-accessible e-mail
The Web, including Web browsing and Internet commerce
Instant messaging, with contact lists
Peer-to-peer file sharing of MP3s, pioneered by Napster

Interestingly, the first two killer applications came from the research community,
whereas the last two were created by a few young entrepreneurs.
The period from 1995 to 2001 was a roller-coaster ride for the Internet in the
financial markets. Before they were even profitable, hundreds of Internet startups
made initial public offerings and started to be traded in a stock market. Many companies were valued in the billions of dollars without having any significant revenue
streams. The Internet stocks collapsed in 2000–2001, and many startups shut down.
Nevertheless, a number of companies emerged as big winners in the Internet space,
including Microsoft, Cisco, Yahoo, eBay, Google, and Amazon.

1.7.5 The New Millennium
In the first two decades of the 21st century, perhaps no other technology has transformed society more than the Internet along with Internet-connected smartphones.
And innovation in computer networking continues at a rapid pace. Advances are
being made on all fronts, including deployments of faster routers and higher transmission speeds in both access networks and in network backbones. But the following
developments merit special attention:
• Since the beginning of the millennium, we have been seeing aggressive deployment of broadband Internet access to homes—not only cable modems and DSL
but also fiber to the home, and now 5G fixed wireless as discussed in Section 1.2.
This high-speed Internet access has set the stage for a wealth of video applications, including the distribution of user-generated video (for example, YouTube),
on-demand streaming of movies and television shows (e.g., Netflix), and multiperson video conference (e.g., Skype, Facetime, and Google Hangouts).
• The increasing ubiquity of high-speed wireless Internet access is not only making
it possible to remain constantly connected while on the move, but also enabling
new location-specific applications such as Yelp, Tinder, and Waz. The number of
wireless devices connecting to the Internet surpassed the number of wired devices

63

64

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

in 2011. This high-speed wireless access has set the stage for the rapid emergence
of hand-held computers (iPhones, Androids, iPads, and so on), which enjoy constant and untethered access to the Internet.
• Online social networks—such as Facebook, Instagram, Twitter, and WeChat
(hugely popular in China)—have created massive people networks on top of the
Internet. Many of these social networks are extensively used for messaging as
well as photo sharing. Many Internet users today “live” primarily within one or
more social networks. Through their APIs, the online social networks create platforms for new networked applications, including mobile payments and distributed games.
• As discussed in Section 1.3.3, online service providers, such as Google and
Microsoft, have deployed their own extensive private networks, which not only
connect together their globally distributed data centers, but are used to bypass the
Internet as much as possible by peering directly with lower-tier ISPs. As a result,
Google provides search results and e-mail access almost instantaneously, as if
their data centers were running within one’s own computer.
• Many Internet commerce companies are now running their applications in the
“cloud”—such as in Amazon’s EC2, in Microsoft’s Azure, or in the Alibaba
Cloud. Many companies and universities have also migrated their Internet
applications (e.g., e-mail and Web hosting) to the cloud. Cloud companies not
only provide applications scalable computing and storage environments, but
also provide the applications implicit access to their high-performance private
networks.

1.8 Summary
In this chapter, we’ve covered a tremendous amount of material! We’ve looked at
the various pieces of hardware and software that make up the Internet in particular
and computer networks in general. We started at the edge of the network, looking at end systems and applications, and at the transport service provided to the
applications running on the end systems. We also looked at the link-layer technologies and physical media typically found in the access network. We then dove
deeper inside the network, into the network core, identifying packet switching and
circuit switching as the two basic approaches for transporting data through a telecommunication network, and we examined the strengths and weaknesses of each
approach. We also examined the structure of the global Internet, learning that the
Internet is a network of networks. We saw that the Internet’s hierarchical structure,
consisting of higher- and lower-tier ISPs, has allowed it to scale to include thousands of networks.

1.8

In the second part of this introductory chapter, we examined several topics central to the field of computer networking. We first examined the causes of delay,
throughput and packet loss in a packet-switched network. We developed simple
quantitative models for transmission, propagation, and queuing delays as well as
for throughput; we’ll make extensive use of these delay models in the homework
problems throughout this book. Next we examined protocol layering and service
models, key architectural principles in networking that we will also refer back to
throughout this book. We also surveyed some of the more prevalent security attacks
in the Internet day. We finished our introduction to networking with a brief history
of computer networking. The first chapter in itself constitutes a mini-course in computer networking.
So, we have indeed covered a tremendous amount of ground in this first chapter!
If you’re a bit overwhelmed, don’t worry. In the following chapters, we’ll revisit all
of these ideas, covering them in much more detail (that’s a promise, not a threat!).
At this point, we hope you leave this chapter with a still-developing intuition for the
pieces that make up a network, a still-developing command of the vocabulary of
networking (don’t be shy about referring back to this chapter), and an ever-growing
desire to learn more about networking. That’s the task ahead of us for the rest of this
book.

Road-Mapping This Book
Before starting any trip, you should always glance at a road map in order to
become familiar with the major roads and junctures that lie ahead. For the trip
we are about to embark on, the ultimate destination is a deep understanding of
the how, what, and why of computer networks. Our road map is the sequence of
chapters of this book:
1.
2.
3.
4.
5.
6.
7.
8.

Computer Networks and the Internet
Application Layer
Transport Layer
Network Layer: Data Plane
Network Layer: Control Plane
The Link Layer and LANs
Wireless and Mobile Networks
Security in Computer Networks

Chapters 2 through 6 are the five core chapters of this book. You should notice
that these chapters are organized around the top four layers of the five-layer Internet
protocol. Further note that our journey will begin at the top of the Internet protocol
stack, namely, the application layer, and will work its way downward. The rationale
behind this top-down journey is that once we understand the applications, we can

•

SUMMARY

65

66

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

understand the network services needed to support these applications. We can then,
in turn, examine the various ways in which such services might be implemented by
a network architecture. Covering applications early thus provides motivation for the
remainder of the text.
The second half of the book—Chapters 7 and 8—zooms in on two enormously important (and somewhat independent) topics in modern computer networking. In Chapter 7, we examine wireless and mobile networks, including
wireless LANs (including WiFi and Bluetooth), Cellular networks (including
4G and 5G), and mobility. Chapter 8, which addresses security in computer networks, first looks at the underpinnings of encryption and network security, and
then we examine how the basic theory is being applied in a broad range of Internet contexts.

Homework Problems and Questions
Chapter 1 Review Questions
SECTION 1.1

R1. What is the difference between a host and an end system? List several different types of end systems. Is a Web server an end system?
R2. The word protocol is often used to describe diplomatic relations. How does
Wikipedia describe diplomatic protocol?
R3. Why are standards important for protocols?
SECTION 1.2

R4. List four access technologies. Classify each one as home access, enterprise
access, or wide-area wireless access.
R5. Is HFC transmission rate dedicated or shared among users? Are collisions
possible in a downstream HFC channel? Why or why not?
R6. List the available residential access technologies in your city. For each
type of access, provide the advertised downstream rate, upstream rate, and
monthly price.
R7. What is the transmission rate of Ethernet LANs?
R8. What are some of the physical media that Ethernet can run over?
R9. HFC, DSL, and FTTH are all used for residential access. For each of
these access technologies, provide a range of transmission rates and
comment on whether the transmission rate is shared or dedicated.
R10. Describe the most popular wireless Internet access technologies today.
Compare and contrast them.

HOMEWORK PROBLEMS AND QUESTIONS

SECTION 1.3

R11. Suppose there is exactly one packet switch between a sending host and a
receiving host. The transmission rates between the sending host and the
switch and between the switch and the receiving host are R1 and R2, respectively. Assuming that the switch uses store-and-forward packet switching,
what is the total end-to-end delay to send a packet of length L? (Ignore queuing, propagation delay, and processing delay.)
R12. What advantage does a circuit-switched network have over a packet-switched network? What advantages does TDM have over FDM in a circuit-switched network?
R13. Suppose users share a 2 Mbps link. Also suppose each user transmits continuously at 1 Mbps when transmitting, but each user transmits only 20 percent
of the time. (See the discussion of statistical multiplexing in Section 1.3.)
a. When circuit switching is used, how many users can be supported?
b. For the remainder of this problem, suppose packet switching is used. Why
will there be essentially no queuing delay before the link if two or fewer
users transmit at the same time? Why will there be a queuing delay if
three users transmit at the same time?
c. Find the probability that a given user is transmitting.
d. Suppose now there are three users. Find the probability that at any given
time, all three users are transmitting simultaneously. Find the fraction of
time during which the queue grows.
R14. Why will two ISPs at the same level of the hierarchy often peer with each
other? How does an IXP earn money?
R15. Some content providers have created their own networks. Describe Google’s
network. What motivates content providers to create these networks?
SECTION 1.4

R16. Consider sending a packet from a source host to a destination host over a
fixed route. List the delay components in the end-to-end delay. Which of
these delays are constant and which are variable?
R17. Visit the Transmission Versus Propagation Delay interactive animation at
the companion Web site. Among the rates, propagation delay, and packet
sizes available, find a combination for which the sender finishes transmitting
before the first bit of the packet reaches the receiver. Find another combination for which the first bit of the packet reaches the receiver before the sender
finishes transmitting.
R18. How long does it take a packet of length 1,000 bytes to propagate over a
link of distance 2,500 km, propagation speed 2.5 # 108 m/s, and transmission
rate 2 Mbps? More generally, how long does it take a packet of length L to
propagate over a link of distance d, propagation speed s, and transmission

67

68

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

rate R bps? Does this delay depend on packet length? Does this delay depend
on transmission rate?
R19. Suppose Host A wants to send a large file to Host B. The path from Host A to Host
B has three links, of rates R1 = 500 kbps, R2 = 2 Mbps, and R3 = 1 Mbps.
a. Assuming no other traffic in the network, what is the throughput for the
file transfer?
b. Suppose the file is 4 million bytes. Dividing the file size by the throughput, roughly how long will it take to transfer the file to Host B?
c. Repeat (a) and (b), but now with R2 reduced to 100 kbps.
R20. Suppose end system A wants to send a large file to end system B. At a very
high level, describe how end system A creates packets from the file. When
one of these packets arrives to a router, what information in the packet does
the router use to determine the link onto which the packet is forwarded?
Why is packet switching in the Internet analogous to driving from one city to
another and asking directions along the way?
R21. Visit the Queuing and Loss interactive animation at the companion Web site.
What is the maximum emission rate and the minimum transmission rate?
With those rates, what is the traffic intensity? Run the interactive animation
with these rates and determine how long it takes for packet loss to occur.
Then repeat the experiment a second time and determine again how long it
takes for packet loss to occur. Are the values different? Why or why not?
SECTION 1.5

R22. List five tasks that a layer can perform. Is it possible that one (or more) of
these tasks could be performed by two (or more) layers?
R23. What are the five layers in the Internet protocol stack? What are the principal
responsibilities of each of these layers?
R24. What is an application-layer message? A transport-layer segment? A network-layer datagram? A link-layer frame?
R25. Which layers in the Internet protocol stack does a router process? Which layers does a link-layer switch process? Which layers does a host process?
SECTION 1.6

R26. What is self-replicating malware?
R27. Describe how a botnet can be created and how it can be used for a DDoS attack.
R28. Suppose Alice and Bob are sending packets to each other over a computer
network. Suppose Trudy positions herself in the network so that she can
capture all the packets sent by Alice and send whatever she wants to Bob; she
can also capture all the packets sent by Bob and send whatever she wants to
Alice. List some of the malicious things Trudy can do from this position.

PROBLEMS

Problems
P1. Design and describe an application-level protocol to be used between an
automatic teller machine and a bank’s centralized computer. Your protocol
should allow a user’s card and password to be verified, the account balance (which is maintained at the centralized computer) to be queried, and an
account withdrawal to be made (that is, money disbursed to the user). Your
protocol entities should be able to handle the all-too-common case in which
there is not enough money in the account to cover the withdrawal. Specify
your protocol by listing the messages exchanged and the action taken by the
automatic teller machine or the bank’s centralized computer on transmission
and receipt of messages. Sketch the operation of your protocol for the case of
a simple withdrawal with no errors, using a diagram similar to that in Figure 1.2.
Explicitly state the assumptions made by your protocol about the underlying
end-to-end transport service.
P2. Equation 1.1 gives a formula for the end-to-end delay of sending one packet
of length L over N links of transmission rate R. Generalize this formula for
sending P such packets back-to-back over the N links.
P3. Consider an application that transmits data at a steady rate (for example, the
sender generates an N-bit unit of data every k time units, where k is small
and fixed). Also, when such an application starts, it will continue running
for a relatively long period of time. Answer the following questions, briefly
justifying your answer:
a. Would a packet-switched network or a circuit-switched network be more
appropriate for this application? Why?
b. Suppose that a packet-switched network is used and the only traffic in
this network comes from such applications as described above. Furthermore, assume that the sum of the application data rates is less than the
capacities of each and every link. Is some form of congestion control
needed? Why?
P4. Consider the circuit-switched network in Figure 1.13. Recall that there are
four circuits on each link. Label the four switches A, B, C, and D, going in
the clockwise direction.
a. What is the maximum number of simultaneous connections that can be in
progress at any one time in this network?
b. Suppose that all connections are between switches A and C. What is the
maximum number of simultaneous connections that can be in progress?
c. Suppose we want to make four connections between switches A and C,
and another four connections between switches B and D. Can we
route these calls through the four links to accommodate all eight
connections?

69

70

CHAPTER 1

VideoNote
Exploring propagation
delay and transmission
delay

•

COMPUTER NETWORKS AND THE INTERNET

P5. Review the car-caravan analogy in Section 1.4. Assume a propagation speed
of 100 km/hour.
a. Suppose the caravan travels 175 km, beginning in front of one tollbooth,
passing through a second tollbooth, and finishing just after a third tollbooth. What is the end-to-end delay?
b. Repeat (a), now assuming that there are eight cars in the caravan instead
of ten.
P6. This elementary problem begins to explore propagation delay and transmission delay, two central concepts in data networking. Consider two hosts, A
and B, connected by a single link of rate R bps. Suppose that the two hosts
are separated by m meters, and suppose the propagation speed along the link
is s meters/sec. Host A is to send a packet of size L bits to Host B.
a. Express the propagation delay, dprop, in terms of m and s.
b. Determine the transmission time of the packet, dtrans, in terms of L and R.
c. Ignoring processing and queuing delays, obtain an expression for the endto-end delay.
d. Suppose Host A begins to transmit the packet at time t = 0. At time t =
dtrans, where is the last bit of the packet?
e. Suppose dprop is greater than dtrans. At time t = dtrans, where is the first
bit of the packet?
f. Suppose dprop is less than dtrans. At time t = dtrans, where is the first bit of
the packet?
g. Suppose s = 2.5 # 108, L = 1500 bytes, and R = 10 Mbps. Find the
distance m so that dprop equals dtrans.
P7. In this problem, we consider sending real-time voice from Host A to Host B
over a packet-switched network (VoIP). Host A converts analog voice to a
digital 64 kbps bit stream on the fly. Host A then groups the bits into 56-byte
packets. There is one link between Hosts A and B; its transmission rate is
10 Mbps and its propagation delay is 10 msec. As soon as Host A gathers a
packet, it sends it to Host B. As soon as Host B receives an entire packet, it
converts the packet’s bits to an analog signal. How much time elapses from
the time a bit is created (from the original analog signal at Host A) until the
bit is decoded (as part of the analog signal at Host B)?
P8. Suppose users share a 10 Mbps link. Also suppose each user requires 200 kbps
when transmitting, but each user transmits only 10 percent of the time. (See
the discussion of packet switching versus circuit switching in Section 1.3.)
a. When circuit switching is used, how many users can be supported?
b. For the remainder of this problem, suppose packet switching is used. Find
the probability that a given user is transmitting.

PROBLEMS

c. Suppose there are 120 users. Find the probability that at any given time,
exactly n users are transmitting simultaneously. (Hint: Use the binomial
distribution.)
d. Find the probability that there are 51 or more users transmitting
simultaneously.
P9. Consider the discussion in Section 1.3 of packet switching versus circuit switching in which an example is provided with a 1 Mbps link. Users are generating
data at a rate of 100 kbps when busy, but are busy generating data only with
probability p = 0.1. Suppose that the 1 Mbps link is replaced by a 1 Gbps link.
a. What is N, the maximum number of users that can be supported simultaneously under circuit switching?
b. Now consider packet switching and a user population of M users. Give a
formula (in terms of p, M, N) for the probability that more than N users
are sending data.
P10. Consider a packet of length L that begins at end system A and travels over
three links to a destination end system. These three links are connected by
two packet switches. Let di, si, and Ri denote the length, propagation speed,
and the transmission rate of link i, for i = 1, 2, 3. The packet switch delays
each packet by dproc. Assuming no queuing delays, in terms of di, si, Ri,
(i = 1, 2, 3), and L, what is the total end-to-end delay for the packet? Suppose now the packet is 1,500 bytes, the propagation speed on all three links is
2.5 # 108m/s, the transmission rates of all three links are 2.5 Mbps, the packet
switch processing delay is 3 msec, the length of the first link is 5,000 km, the
length of the second link is 4,000 km, and the length of the last link is 1,000
km. For these values, what is the end-to-end delay?
P11. In the above problem, suppose R1 = R2 = R3 = R and dproc = 0. Further
suppose that the packet switch does not store-and-forward packets but instead
immediately transmits each bit it receives before waiting for the entire packet
to arrive. What is the end-to-end delay?
P12. A packet switch receives a packet and determines the outbound link to which
the packet should be forwarded. When the packet arrives, one other packet is
halfway done being transmitted on this outbound link and four other packets are
waiting to be transmitted. Packets are transmitted in order of arrival. Suppose
all packets are 1,500 bytes and the link rate is 2.5 Mbps. What is the queuing
delay for the packet? More generally, what is the queuing delay when all packets
have length L, the transmission rate is R, x bits of the currently-being-transmitted
packet have been transmitted, and n packets are already in the queue?
P13. (a) Suppose N packets arrive simultaneously to a link at which no packets
are currently being transmitted or queued. Each packet is of length L and
the link has transmission rate R. What is the average queuing delay for
the N packets?

71

72

CHAPTER 1

VideoNote
Using Traceroute to
discover network
paths and measure
network delay

•

COMPUTER NETWORKS AND THE INTERNET

(b) Now suppose that N such packets arrive to the link every LN/R seconds.
What is the average queuing delay of a packet?
P14. Consider the queuing delay in a router buffer. Let I denote traffic intensity;
that is, I = La/R. Suppose that the queuing delay takes the form IL/R (1 - I)
for I 6 1.
a. Provide a formula for the total delay, that is, the queuing delay plus the
transmission delay.
b. Plot the total delay as a function of L/R.
P15. Let a denote the rate of packets arriving at a link in packets/sec, and let µ
denote the link’s transmission rate in packets/sec. Based on the formula for
the total delay (i.e., the queuing delay plus the transmission delay) derived
in the previous problem, derive a formula for the total delay in terms of a
and µ.
P16. Consider a router buffer preceding an outbound link. In this problem, you
will use Little’s formula, a famous formula from queuing theory. Let N
denote the average number of packets in the buffer plus the packet being
transmitted. Let a denote the rate of packets arriving at the link. Let d denote
the average total delay (i.e., the queuing delay plus the transmission delay)
experienced by a packet. Little’s formula is N = a # d. Suppose that on
average, the buffer contains 100 packets, and the average packet queuing
delay is 20 msec. The link’s transmission rate is 100 packets/sec. Using
Little’s formula, what is the average packet arrival rate, assuming there is
no packet loss?
P17. a. Generalize Equation 1.2 in Section 1.4.3 for heterogeneous processing
rates, transmission rates, and propagation delays.
b. Repeat (a), but now also suppose that there is an average queuing delay of
dqueue at each node.
P18. Perform a Traceroute between source and destination on the same continent
at three different hours of the day.
a. Find the average and standard deviation of the round-trip delays at each of
the three hours.
b. Find the number of routers in the path at each of the three hours. Did the
paths change during any of the hours?
c. Try to identify the number of ISP networks that the Traceroute packets
pass through from source to destination. Routers with similar names and/
or similar IP addresses should be considered as part of the same ISP. In
your experiments, do the largest delays occur at the peering interfaces
between adjacent ISPs?
d. Repeat the above for a source and destination on different continents.
Compare the intra-continent and inter-continent results.

PROBLEMS

P19. Metcalfe’s law states the value of a computer network is proportional to
the square of the number of connected users of the system. Let n denote the
number of users in a computer network. Assuming each user sends one message to each of the other users, how many messages will be sent? Does your
answer support Metcalfe’s law?
P20. Consider the throughput example corresponding to Figure 1.20(b). Now
suppose that there are M client-server pairs rather than 10. Denote Rs, Rc,
and R for the rates of the server links, client links, and network link. Assume
all other links have abundant capacity and that there is no other traffic in the
network besides the traffic generated by the M client-server pairs. Derive a
general expression for throughput in terms of Rs, Rc, R, and M.
P21. Consider Figure 1.19(b). Now suppose that there are M paths between the
server and the client. No two paths share any link. Path k (k = 1, c, M)
consists of N links with transmission rates Rk1, Rk2, c, RkN . If the server can
only use one path to send data to the client, what is the maximum throughput
that the server can achieve? If the server can use all M paths to send data,
what is the maximum throughput that the server can achieve?
P22. Consider Figure 1.19(b). Suppose that each link between the server and the
client has a packet loss probability p, and the packet loss probabilities for
these links are independent. What is the probability that a packet (sent by the
server) is successfully received by the receiver? If a packet is lost in the path
from the server to the client, then the server will re-transmit the packet. On
average, how many times will the server re-transmit the packet in order for
the client to successfully receive the packet?
P23. Consider Figure 1.19(a). Assume that we know the bottleneck link along the
path from the server to the client is the first link with rate Rs bits/sec. Suppose
we send a pair of packets back to back from the server to the client, and there
is no other traffic on this path. Assume each packet of size L bits, and both
links have the same propagation delay dprop.
a. What is the packet inter-arrival time at the destination? That is, how much
time elapses from when the last bit of the first packet arrives until the last
bit of the second packet arrives?
b. Now assume that the second link is the bottleneck link (i.e., Rc 6 Rs). Is
it possible that the second packet queues at the input queue of the second
link? Explain. Now suppose that the server sends the second packet T
seconds after sending the first packet. How large must T be to ensure no
queuing before the second link? Explain.
P24. Suppose you would like to urgently deliver 50 terabytes data from Boston to
Los Angeles. You have available a 100 Mbps dedicated link for data transfer.
Would you prefer to transmit the data via this link or instead use FedEx overnight delivery? Explain.

73

74

CHAPTER 1

•

COMPUTER NETWORKS AND THE INTERNET

P25. Suppose two hosts, A and B, are separated by 20,000 kilometers and are connected by a direct link of R = 5 Mbps. Suppose the propagation speed over
the link is 2.5 # 108 meters/sec.
a. Calculate the bandwidth-delay product, R # dprop.
b. Consider sending a file of 800,000 bits from Host A to Host B. Suppose
the file is sent continuously as one large message. What is the maximum
number of bits that will be in the link at any given time?
c. Provide an interpretation of the bandwidth-delay product.
d. What is the width (in meters) of a bit in the link? Is it longer than a
football field?
e. Derive a general expression for the width of a bit in terms of the
propagation speed s, the transmission rate R, and the length of the
link m.
P26. Referring to problem P24, suppose we can modify R. For what value of R is
the width of a bit as long as the length of the link?
P27. Consider problem P24 but now with a link of R = 500 Mbps.
a. Calculate the bandwidth-delay product, R # dprop.
b. Consider sending a file of 800,000 bits from Host A to Host B. Suppose
the file is sent continuously as one big message. What is the maximum
number of bits that will be in the link at any given time?
c. What is the width (in meters) of a bit in the link?
P28. Refer again to problem P24.
a. How long does it take to send the file, assuming it is sent continuously?
b. Suppose now the file is broken up into 20 packets with each packet
containing 40,000 bits. Suppose that each packet is acknowledged by
the receiver and the transmission time of an acknowledgment packet is
negligible. Finally, assume that the sender cannot send a packet until the
preceding one is acknowledged. How long does it take to send the file?
c. Compare the results from (a) and (b).
P29. Suppose there is a 10 Mbps microwave link between a geostationary
satellite and its base station on Earth. Every minute the satellite takes a digital photo and sends it to the base station. Assume a propagation speed
of 2.4 # 108 meters/sec.
a. What is the propagation delay of the link?
b. What is the bandwidth-delay product, R # dprop?
c. Let x denote the size of the photo. What is the minimum value of x for the
microwave link to be continuously transmitting?

PROBLEMS

P30. Consider the airline travel analogy in our discussion of layering in Section 1.5,
and the addition of headers to protocol data units as they flow down the protocol stack. Is there an equivalent notion of header information that is added to
passengers and baggage as they move down the airline protocol stack?
P31. In modern packet-switched networks, including the Internet, the source host segments long, application-layer messages (for example, an image or a music file)
into smaller packets and sends the packets into the network. The receiver then
reassembles the packets back into the original message. We refer to this process as
message segmentation. Figure 1.27 illustrates the end-to-end transport of a message
with and without message segmentation. Consider a message that is 106 bits
long that is to be sent from source to destination in Figure 1.27. Suppose each
link in the figure is 5 Mbps. Ignore propagation, queuing, and processing delays.
a. Consider sending the message from source to destination without message
segmentation. How long does it take to move the message from the source
host to the first packet switch? Keeping in mind that each switch uses
store-and-forward packet switching, what is the total time to move the
message from source host to destination host?
b. Now suppose that the message is segmented into 100 packets, with each
packet being 10,000 bits long. How long does it take to move the first
packet from source host to the first switch? When the first packet is being
sent from the first switch to the second switch, the second packet is being
sent from the source host to the first switch. At what time will the second
packet be fully received at the first switch?
c. How long does it take to move the file from source host to destination
host when message segmentation is used? Compare this result with your
answer in part (a) and comment.
Message

a.

Source

Packet switch

Packet switch

Destination

Packet switch

Destination

Packet

b.

Source

Packet switch

Figure 1.27 ♦ End-to-end message transport: (a) without message
segmentation; (b) with message segmentation

75

